import requests
import json
import os

from pathlib import Path
script_path = os.path.dirname(os.path.abspath(__file__))
os.chdir(script_path)
print(script_path)
from langchain.chat_models import ErnieBotChat
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from gradio.inputs import Textbox

from infer_file import Infer_Fun
from utils.hparams import set_hparams
from utils.hparams import hparams as hp
import importlib
from sklearn.cluster import MiniBatchKMeans
import faiss
import jieba
import time
import re
import shlex
import locale
import random
import aistudio
import yaml
import numpy as np
import soundfile as sf
import glob
import subprocess
import sys
import time
import traceback

from time import sleep
import librosa
import soundfile
import torch
import wave
import ast
from pydub import AudioSegment
from subprocess import Popen
from random import shuffle
import warnings
import traceback
import threading
from pypinyin import pinyin, lazy_pinyin
from concurrent.futures import ProcessPoolExecutor

from song_templates import lyrics_dict, notes_duration_dict, notes_dict, lyrics_slot_dict, Songs_CN_dict, \
    ONOMATOPOEIC_WORDS, Songs_ST_dict, Songs_V_dict, Singer_F_dict
from song_prompt import GEN_LYRICS_MAIN, WORD_REPLACE, THEME_EXTEND, SUMMARY

import logging
import os
import pathlib
import platform
if platform.system().lower() == 'windows':
    temp = pathlib.PosixPath
    pathlib.PosixPath = pathlib.WindowsPath
elif platform.system().lower() == 'linux':
    temp = pathlib.WindowsPath
    pathlib.WindowsPath = pathlib.PosixPath
os.environ["PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION"] = "python"
os.environ["PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION"] = "python"
os.environ["weight_root"] = "assets/weights"
os.environ["weight_uvr5_root"] = "assets/uvr5_weights"
os.environ["index_root"] = "logs"
os.environ["rmvpe_root"] = "assets/rmvpe"

import torch
import multiprocessing


from configs.config import Config
import gradio as gr
import pathlib

import logging

import os
import sys
from dotenv import load_dotenv
from lyrics_to_melody import lyrics_to_melody, SongsType

now_dir = os.getcwd()
sys.path.append(now_dir)
load_dotenv()
from infer.modules.vc.modules import VC

import fairseq
import warnings
import shutil
from subprocess import Popen

logging.getLogger("numba").setLevel(logging.WARNING)

logger = logging.getLogger(__name__)

tmp = os.path.join(now_dir, "TEMP")
shutil.rmtree(tmp, ignore_errors=True)
shutil.rmtree("%s/runtime/Lib/site-packages/infer_pack" % (now_dir), ignore_errors=True)
shutil.rmtree("%s/runtime/Lib/site-packages/uvr5_pack" % (now_dir), ignore_errors=True)
os.makedirs(tmp, exist_ok=True)
os.makedirs(os.path.join(now_dir, "logs"), exist_ok=True)
os.makedirs(os.path.join(now_dir, "assets/weights"), exist_ok=True)
os.environ["TEMP"] = tmp
warnings.filterwarnings("ignore")
torch.manual_seed(114514)


config = Config()
vc = VC(config)


training_threadpool = ProcessPoolExecutor(max_workers=1)


TRAIN_DATA = """
å½“æˆ‘ç¬¬ä¸€æ¬¡è§åˆ°é‚£åªå°ç‹—æ—¶ï¼Œå®ƒæ­£èœ·ç¼©åœ¨è¡—è§’çš„ä¸€ä¸ªç ´çº¸ç®±é‡Œï¼Œå°å°çš„èº«ä½“é¢¤æŠ–ç€ï¼Œæ¹¿æ¼‰æ¼‰çš„çœ¼ç›é‡Œå……æ»¡äº†ææƒ§å’ŒæœŸå¾…ã€‚å®ƒçš„æ¯›å‘è“¬æ¾ï¼Œä½†å·²ç»è¢«æ±¡å¢æŸ“å¾—æ–‘é©³ã€‚æˆ‘ä¼¸å‡ºæ‰‹ï¼Œå®ƒç•ç¼©äº†ä¸€ä¸‹ï¼Œä½†å¾ˆå¿«ä¾¿åœ¨æˆ‘çš„æ‰‹æŒä¸‹è½»è½»æ‘©æ“¦ï¼Œå‘å‡ºç»†å¾®çš„å‘œå’½å£°ã€‚

é‚£æ˜¯ä¸€ä¸ªå¯’å†·çš„å†¬æ—¥ï¼Œé£åˆºéª¨èˆ¬åœ°å¹ç€ã€‚æˆ‘è¹²ä¸‹èº«ï¼Œå°å¿ƒç¿¼ç¿¼åœ°æŠŠå®ƒæŠ±èµ·æ¥ï¼Œå®ƒçš„ä½“é‡è½»å¾—ä»¤äººåƒæƒŠã€‚æˆ‘æŠŠå®ƒå¸¦å›äº†å®¶ï¼Œç”¨æ¸©æš–çš„æ°´æ…¢æ…¢æ¸…æ´—æ‰å®ƒèº«ä¸Šçš„æ±¡å¢ï¼Œå°ç‹—åœ¨æ°´ä¸­é¢¤æŠ–ï¼Œä½†å®ƒçš„çœ¼ç›é‡Œé—ªçƒç€å¯¹ç”Ÿå‘½æ–°å¸Œæœ›çš„å…‰èŠ’ã€‚

æˆ‘ç»™å®ƒå–åå«â€œå¥‡å¥‡â€ã€‚å¥‡å¥‡å¾ˆå¿«å°±é€‚åº”äº†æ–°å®¶ï¼Œå®ƒæ´»æ³¼å¯çˆ±ï¼Œæ€»æ˜¯å›´ç€æˆ‘è½¬ï¼Œä»¿ä½›å®ƒèƒ½ç†è§£æˆ‘æ‰€æœ‰çš„æƒ…ç»ªã€‚æ¯å½“æˆ‘ä¸‹ç­å›å®¶ï¼Œå®ƒæ€»æ˜¯ç¬¬ä¸€ä¸ªè¿ä¸Šæ¥ï¼Œæ‘‡ç€å°¾å·´ï¼Œç”¨å®ƒé‚£æ¹¿æ¼‰æ¼‰çš„é¼»å­è¹­æˆ‘çš„æ‰‹ã€‚åœ¨å®ƒçš„é™ªä¼´ä¸‹ï¼Œæˆ‘å†ä¹Ÿä¸è§‰å¾—å­¤ç‹¬å’Œå¯‚å¯ã€‚

å¥‡å¥‡å¯¹ä¸–ç•Œå……æ»¡äº†å¥½å¥‡ï¼Œæ¯å½“æˆ‘ä»¬ä¸€èµ·æ•£æ­¥æ—¶ï¼Œå®ƒæ€»æ˜¯å…´å¥‹åœ°è·‘æ¥è·‘å»ï¼Œå¯¹æ¯ä¸€æ ªè‰ã€æ¯ä¸€ä¸ªè§’è½éƒ½è¡¨ç°å‡ºæ— æ¯”çš„å…´è¶£ã€‚å®ƒçš„çœ¼ç›é‡Œæ€»æ˜¯å……æ»¡äº†çƒ­æƒ…å’Œå¥½å¥‡ï¼Œå¥½åƒåœ¨è¯´ï¼šâ€œè¿™ä¸ªä¸–ç•Œæ˜¯å¦‚æ­¤ç¾å¦™ã€‚â€

æœ‰ä¸€æ¬¡ï¼Œæˆ‘å¸¦å®ƒå»å…¬å›­ç©è€ã€‚å¥‡å¥‡æ¬¢å¿«åœ°å¥”è·‘åœ¨è‰åœ°ä¸Šï¼Œçªç„¶ï¼Œå®ƒåœä¸‹æ¥ï¼Œå¯¹ç€ä¸€åªè´è¶æ‘‡å°¾å·´ã€‚é‚£ä¸€åˆ»ï¼Œæˆ‘è¢«å®ƒçº¯çœŸçš„å¿«ä¹æ·±æ·±æ„ŸæŸ“ï¼Œå¿˜è®°äº†ç”Ÿæ´»çš„å‹åŠ›å’Œçƒ¦æ¼ï¼Œåªæƒ³å’Œå®ƒä¸€èµ·åœ¨è¿™ç‰‡ç»¿åœ°ä¸Šè‡ªç”±åœ°å¥”è·‘ã€‚

å¥‡å¥‡ä¸ä»…ç»™æˆ‘çš„ç”Ÿæ´»å¸¦æ¥äº†æ¬¢ä¹ï¼Œå®ƒè¿˜æ•™ä¼šäº†æˆ‘çˆ±å’Œè´£ä»»ã€‚æœ‰æ—¶ï¼Œå½“æˆ‘çœ‹ç€å®ƒç†Ÿç¡çš„æ ·å­ï¼Œæˆ‘ä¼šæƒ³ï¼Œå®ƒæ˜¯å¦‚æ­¤ä¾èµ–æˆ‘ï¼Œæˆ‘çš„ä¸€ä¸ªå°åŠ¨ä½œï¼Œä¸€ä¸ªå†³å®šï¼Œéƒ½ä¼šå½±å“åˆ°å®ƒçš„ç”Ÿæ´»ã€‚æˆ‘å­¦ä¼šäº†æ›´åŠ å…³å¿ƒå’Œä½“è´´ï¼Œä¸å†åªæ˜¯ä¸ºè‡ªå·±è€Œæ´»ã€‚

éšç€æ—¶é—´çš„æµé€ï¼Œå¥‡å¥‡ä»ä¸€åªè„†å¼±çš„å°ç‹—é•¿æˆäº†ä¸€åªå¥åº·ã€å¿«ä¹çš„ç‹—ã€‚æ¯å½“æˆ‘æ„Ÿåˆ°ç–²å€¦æˆ–æ²®ä¸§æ—¶ï¼Œåªéœ€è¦çœ‹çœ‹å¥‡å¥‡é‚£å……æ»¡æ´»åŠ›å’Œä¹è§‚çš„çœ¼ç¥ï¼Œæˆ‘çš„å¿ƒæƒ…å°±ä¼šå¤§ä¸ºå¥½è½¬ã€‚å®ƒæ•™ä¼šäº†æˆ‘ï¼Œæ— è®ºç”Ÿæ´»å¤šä¹ˆè‰°éš¾ï¼Œæ€»æœ‰å¸Œæœ›å’Œå¿«ä¹åœ¨ç­‰ç€æˆ‘ä»¬ã€‚

ç°åœ¨ï¼Œæˆ‘å’Œå¥‡å¥‡æ˜¯ä¸å¯åˆ†å‰²çš„æœ‹å‹ã€‚å®ƒä¸ä»…æ˜¯æˆ‘çš„å® ç‰©ï¼Œæ›´æ˜¯æˆ‘çš„å®¶äººï¼Œæˆ‘çš„ä¼™ä¼´ã€‚æˆ‘æ„Ÿæ¿€å‘½è¿è®©æˆ‘é‡åˆ°äº†å¥‡å¥‡ï¼Œå®ƒç”¨å®ƒçš„æ–¹å¼æ”¹å˜äº†æˆ‘çš„ä¸–ç•Œï¼Œç»™æˆ‘çš„ç”Ÿæ´»å¢æ·»äº†æ— å°½çš„è‰²å½©ã€‚

æˆ‘å¸¸å¸¸æƒ³ï¼Œå¦‚æœä¸æ˜¯é‚£å¤©æˆ‘åœ¨è¡—è§’é‡è§äº†å¥‡å¥‡ï¼Œæˆ‘çš„ç”Ÿæ´»ä¼šæ˜¯æ€æ ·çš„ä¸€ç•ªæ™¯è±¡ã€‚ä¹Ÿè®¸ï¼Œæ›´åŠ å¹³æ·¡æ— å¥‡ï¼Œç¼ºå°‘äº†è¿™ä»½ç‰¹åˆ«çš„æƒ…æ„Ÿå’Œé™ªä¼´ã€‚

å¥‡å¥‡çš„åˆ°æ¥ï¼Œè®©æˆ‘çš„ç”Ÿæ´»å˜å¾—ä¸°å¯Œå¤šå½©ï¼Œå……æ»¡äº†çˆ±å’Œæ¬¢ç¬‘ã€‚å®ƒæ•™ä¼šäº†æˆ‘è®¸å¤šå®è´µçš„ç”Ÿæ´»å“²ç†ï¼Œè®©æˆ‘æˆä¸ºäº†ä¸€ä¸ªæ›´å¥½çš„äººã€‚æˆ‘å¸Œæœ›èƒ½å’Œå¥‡å¥‡ä¸€èµ·åº¦è¿‡æ›´å¤šç¾å¥½çš„å²æœˆï¼Œå…±åŒä¹¦å†™æˆ‘ä»¬çš„æ•…äº‹ã€‚

"""



if config.dml == True:

    def forward_dml(ctx, x, scale):
        ctx.scale = scale
        res = x.clone().detach()
        return res

    fairseq.modules.grad_multiply.GradMultiply.forward = forward_dml
# åˆ¤æ–­æ˜¯å¦æœ‰èƒ½ç”¨æ¥è®­ç»ƒå’ŒåŠ é€Ÿæ¨ç†çš„Nå¡
ngpu = torch.cuda.device_count()
gpu_infos = []
mem = []
if_gpu_ok = False

if torch.cuda.is_available() or ngpu != 0:
    for i in range(ngpu):
        gpu_name = torch.cuda.get_device_name(i)
        if any(
            value in gpu_name.upper()
            for value in [
                "10",
                "16",
                "20",
                "30",
                "40",
                "A2",
                "A3",
                "A4",
                "P4",
                "A50",
                "500",
                "A60",
                "70",
                "80",
                "90",
                "M4",
                "T4",
                "TITAN",
            ]
        ):
            # A10#A100#V100#A40#P40#M40#K80#A4500
            if_gpu_ok = True  # è‡³å°‘æœ‰ä¸€å¼ èƒ½ç”¨çš„Nå¡
            gpu_infos.append("%s\t%s" % (i, gpu_name))
            mem.append(
                int(
                    torch.cuda.get_device_properties(i).total_memory
                    / 1024
                    / 1024
                    / 1024
                    + 0.4
                )
            )
if if_gpu_ok and len(gpu_infos) > 0:
    gpu_info = "\n".join(gpu_infos)
    default_batch_size = min(mem) // 2
else:
    gpu_info = "å¾ˆé—æ†¾æ‚¨è¿™æ²¡æœ‰èƒ½ç”¨çš„æ˜¾å¡æ¥æ”¯æŒæ‚¨è®­ç»ƒ"
    default_batch_size = 1
gpus = "-".join([i[0] for i in gpu_infos])


class ToolButton(gr.Button, gr.components.FormComponent):
    """Small button with single emoji as text, fits inside gradio forms"""

    def __init__(self, **kwargs):
        super().__init__(variant="tool", **kwargs)

    def get_block_name(self):
        return "button"


config = Config()
vc = VC(config)


thread_count = multiprocessing.cpu_count()

print("Use",thread_count,"cpu cores for computing")

torch.set_num_threads(thread_count)
torch.set_num_interop_threads(thread_count)


device = torch.device("cpu")
if torch.cuda.is_available():
    device = torch.device("cuda", 0)



os.environ["AISTUDIO_LOG"] = "debug"

llm = ErnieBotChat(ernie_client_id='96BMhQM5simx6R97yDl483Zm',
                   ernie_client_secret='9e05mDOjHoyXD7Sb9GA1l420uaZ6vGMo',
                   model_name='ERNIE-Bot-4',
                   top_p=0.4)

# æå–jsonæ ¼å¼çš„æ–‡æœ¬
def extract_json(text):
    try:
        pattern = r'```json(.*?)```'
        match = re.search(pattern, text, re.DOTALL)

        if match:
            summary = match.group(1).strip().replace('\n', '')
            return ast.literal_eval(summary)
        return None
    except Exception as e:
        print(e)

# æ‰©å±•ä¸»é¢˜å…³é”®è¯
def extend_theme(theme):
    prompt = PromptTemplate(input_variables=["theme"], template=THEME_EXTEND)
    llm_chain = LLMChain(llm=llm, prompt=prompt)
    results = llm_chain.run(**{"theme": theme})
    results = extract_json(results)
    print("åŸå§‹å…³é”®è¯ï¼š", results)
    return results


def get_summary(theme):
    prompt = PromptTemplate(input_variables=["theme"], template=SUMMARY)
    llm_chain = LLMChain(llm=llm, prompt=prompt)
    results = llm_chain.run(**{"theme": theme})
    results = extract_json(results)
    results = results["summary"]
    print("åŸå§‹æ‘˜è¦ï¼š", results)
    return results



def gen_lyrics(theme, theme_summary, source, source_slot):
    # first trail of lyrics generation
    prompt = PromptTemplate(input_variables=["theme", "theme_summary", "source"], template=GEN_LYRICS_MAIN)
    llm_chain = LLMChain(llm=llm, prompt=prompt)
    results = llm_chain.run(**{"theme": theme, "theme_summary": theme_summary, "source": source})
    results = extract_json(results)
    results = results["lyrics"]
    # print(results)
    # filter results
    ori_list = source.split('\n')
    ori_line_count = len(ori_list) - 2
    punc = '[â€™!"#$%&\'()*+,-./:;<=>?ï¼Ÿ@[\\]^_`{|}~ã€‚ï¼ï¼Œ]+'
    result_pure = re.sub(punc, "", results).replace(" ", "")
    result_pure = result_pure.split('\n')
    if len(result_pure) < ori_line_count:
        resdi = ori_line_count - len(result_pure)
        for i in range(resdi):
            result_pure.append(random.choice(ONOMATOPOEIC_WORDS))
    target_list = result_pure[0:ori_line_count]
    match_list = []
    correct_list = []

    # check words count, adjust words
    for i in range(ori_line_count):
        if len(target_list[i]) != len(ori_list[i + 1]):
            ori_slot_list = source_slot.split('\n')
            tmp_prompt = PromptTemplate(input_variables=["theme", "ori_sentence"], template=WORD_REPLACE)
            tmp_llm_chain = LLMChain(llm=llm, prompt=tmp_prompt)
            tmp_result = tmp_llm_chain.run(**{"theme": theme, "ori_sentence": ori_slot_list[i + 1]})
            tmp_result = extract_json(tmp_result)
            tmp_result = tmp_result["line"]
            tmp_result = tmp_result.replace("\n", "")
            tmp_result_pure = re.sub(punc, "", tmp_result.split('\n')[0])
            if "ï¼š" in tmp_result_pure:
                tmp_result_pure = tmp_result_pure.split("ï¼š")[1]
            target_list[i] = tmp_result_pure.replace(" ", "")
            correct_list.append(i + 1)
        pattern = re.compile(r'[^\u4e00-\u9fa5]')
        chinese = re.sub(pattern, "", target_list[i])
        target_list[i] = chinese
        match_list.append(len(ori_list[i + 1]) - len(target_list[i]))

    # combine with SP
    final_result = 'SP'.join(target_list)
    return target_list, match_list, correct_list, final_result



def retry_gen_lyrics(theme, theme_summary, source, source_slot, max_retries=3, delay_seconds=1):
    retries = 0
    while retries < max_retries:
        try:
            target_list, match_list, correct_list, final_result = gen_lyrics(theme, theme_summary, source, source_slot)
            return target_list, match_list, correct_list, final_result
        except Exception as e:
            print(f"æ­Œè¯ç”Ÿæˆå¤±è´¥ï¼š{e}")
            retries += 1
            if retries < max_retries:
                print(f"è¿›è¡Œç¬¬ {retries} æ¬¡é‡è¯•...")
                time.sleep(delay_seconds)  # å¯é€‰ï¼šå»¶è¿Ÿä¸€å®šæ—¶é—´åå†é‡è¯•
            else:
                print("é‡è¯•æ¬¡æ•°è¾¾åˆ°ä¸Šé™ï¼Œæ”¾å¼ƒé‡è¯•ã€‚")
                break

 
def cut_duration(lyrics, durations):
    durations_lst = []
    idx = 0
    rest = []
    for i in range(len(lyrics)):
        len_lyric = len(lyrics[i])
        if i == 0:
            durations_lst.append(durations[idx:idx + len_lyric])
            rest.append(durations[idx + len_lyric])
        else:
            if i == len(lyrics) - 1:
                durations_lst.append(durations[idx:idx + len_lyric])
            else:
                durations_lst.append(durations[idx:idx + len_lyric])
                rest.append(durations[idx + len_lyric])
        idx += len_lyric + 1
    return durations_lst, rest

def judge_length(word_lst, need_len):
    res = ""
    for word in word_lst:

        tmp_len = len(res) + len(word)
        if tmp_len == need_len:
            res += word
            print("ä¿®æ­£åé•¿åº¦ï¼š{}, æ­Œæ›²æ¨¡æ¿é•¿åº¦ï¼š{}, ä¿®æ­£åæ­Œè¯ï¼š{}".format(len(res), need_len, res))
            return res
        elif tmp_len > need_len:
            resdi = tmp_len - need_len
            if resdi >= 2:
                if need_len - len(res) == 1:
                    res += random.choice(ONOMATOPOEIC_WORDS)
                else:
                    res += word[:-resdi]
            else:
                res = res + word[:-2] + random.choice(ONOMATOPOEIC_WORDS)
            print("ä¿®æ­£åé•¿åº¦ï¼š{}, æ­Œæ›²æ¨¡æ¿é•¿åº¦ï¼š{}, ä¿®æ­£åæ­Œè¯ï¼š{}".format(len(res), need_len, res))
            return res
        else:
            res += word


def gen_notes_and_durations(notes, durations, lyrics, new_lyrics):
    lyrics = lyrics.split("\n")[1:-1]
    new_lyrics = new_lyrics.split("SP")
    notes_o = notes.split(" | rest | ")
    notes = []
    for n in notes_o:
        n = n.split(" | ")
        notes.append(n)
    durations = durations.split(" | ")
    durations, rest = cut_duration(lyrics, durations)
    new_lyrics = new_lyrics[:len(lyrics)]
    durations_res = []
    notes_res = []
    new_lyrics_res = []
    for i in range(len(lyrics)):
        old_len = len(lyrics[i])
        new_len = len(new_lyrics[i])
        if old_len == new_len:
            notes_res.extend(notes[i])
            durations_res.extend(durations[i])
            new_lyrics_res.append(new_lyrics[i])
        elif new_len > old_len:
            residual = new_len - old_len
            if residual >= 2:
                word_lst = jieba.lcut(new_lyrics[i], cut_all=False)
                lyric_i = judge_length(word_lst, old_len)
                new_lyrics_res.append(lyric_i)
                notes_res.extend(notes[i])
                durations_res.extend(durations[i])
            else:
                notes_res.extend(notes[i][:-residual])
                durations_res.extend(durations[i][:-residual])
 
                while residual > 0:
                    if " " in durations[i][-residual] or " " in notes[i][-residual]:
                        print(durations[i][-residual].split(" ")[0], durations[i][-residual].split(" ")[1])
                        notes_res.append(notes[i][-residual].split(" ")[0])
                        notes_res.append(notes[i][-residual].split(" ")[1])
                        durations_res.append(durations[i][-residual].split(" ")[0])
                        durations_res.append(durations[i][-residual].split(" ")[1])
                    else:
                        notes_res.append(notes[i][-residual])
                        notes_res.append(notes[i][-residual])
                        durations_res.append(str(float(durations[i][-residual]) / 2))
                        durations_res.append(str(float(durations[i][-residual]) / 2))
                    residual -= 1
                new_lyrics_res.append(new_lyrics[i])
        else:
            residual = new_len - old_len
            notes_res.extend(notes[i])
            durations_res.extend(durations[i])
            new_lyrics_res.append(new_lyrics[i] + random.choice(ONOMATOPOEIC_WORDS) * abs(residual))
        #print(len(notes_res), len(durations_res), len("".join(new_lyrics_res).replace("SP", "|")))
        #print(new_lyrics_res)
        #print(" | ".join(notes_res))
        #print(" | ".join(durations_res))
        #print("".join(new_lyrics_res))
        if i != len(lyrics) - 1:
            notes_res.append("rest")
            durations_res.append(rest[i])
            new_lyrics_res.append("SP")

    new_lyrics_res = "".join(new_lyrics_res)
    print(len(notes_res), len(durations_res), len(new_lyrics_res.replace("SP", "|")))
    notes_res = " | ".join(notes_res)
    durations_res = " | ".join(durations_res)
    return notes_res, durations_res, new_lyrics_res
def gen_songs_needs(theme, song):
    theme_summary = get_summary(theme)
    target_list, match_list, correct_list, new_lyrics_tmp = retry_gen_lyrics(theme=theme,
                                                                             theme_summary=theme_summary,
                                                                             source=lyrics_dict.get(song),
                                                                             source_slot=lyrics_slot_dict.get(song))
    notes = notes_dict.get(song)
    duration = notes_duration_dict.get(song)
    lyrics = lyrics_dict.get(song)
    if not correct_list:
        notes_res, durations_res, new_lyrics_res = notes, duration, new_lyrics_tmp
    else:
        notes_res, durations_res, new_lyrics_res = gen_notes_and_durations(notes, duration, lyrics, new_lyrics_tmp)
    print("æ–°æ­Œè¯ï¼š{}\næ›²è°±ï¼š{}\næ—¶é•¿ï¼š{}".format(new_lyrics_res, notes_res, durations_res))
    return notes_res, durations_res, new_lyrics_res


class Info:
    def __init__(self) -> None:
        pass

LANGUAGE_LIST = ['zh_CN', 'en_US']
LANGUAGE_ALL = {
    'zh_CN': {
        'SUPER': 'END',
        'LANGUAGE': 'zh_CN',
        'åˆå§‹åŒ–æˆåŠŸ': 'åˆå§‹åŒ–æˆåŠŸ',
        'å°±ç»ª': 'å°±ç»ª',
        'é¢„å¤„ç†-è®­ç»ƒ': 'é¢„å¤„ç†-è®­ç»ƒ',
        'è®­ç»ƒè¯´æ˜': 'è®­ç»ƒè¯´æ˜',
        '### é¢„å¤„ç†å‚æ•°è®¾ç½®': '### é¢„å¤„ç†å‚æ•°è®¾ç½®',
        'æ¨¡å‹åç§°': 'æ¨¡å‹åç§°',
        'f0æå–å™¨': 'f0æå–å™¨',
        'é¢„å¤„ç†çº¿ç¨‹æ•°': 'é¢„å¤„ç†çº¿ç¨‹æ•°',
        '### è®­ç»ƒå‚æ•°è®¾ç½®': '### è®­ç»ƒå‚æ•°è®¾ç½®',
        'å­¦ä¹ ç‡': 'å­¦ä¹ ç‡',
        'æ‰¹å¤§å°': 'æ‰¹å¤§å°',
        'è®­ç»ƒæ—¥å¿—è®°å½•é—´éš”ï¼ˆstepï¼‰': 'è®­ç»ƒæ—¥å¿—è®°å½•é—´éš”ï¼ˆstepï¼‰',
        'éªŒè¯é›†éªŒè¯é—´éš”ï¼ˆepochï¼‰': 'éªŒè¯é›†éªŒè¯é—´éš”ï¼ˆepochï¼‰',
        'æ£€æŸ¥ç‚¹ä¿å­˜é—´éš”ï¼ˆepochï¼‰': 'æ£€æŸ¥ç‚¹ä¿å­˜é—´éš”ï¼ˆepochï¼‰',
        'ä¿ç•™æœ€æ–°çš„æ£€æŸ¥ç‚¹æ–‡ä»¶(0ä¿å­˜å…¨éƒ¨)': 'ä¿ç•™æœ€æ–°çš„æ£€æŸ¥ç‚¹æ–‡ä»¶(0ä¿å­˜å…¨éƒ¨)',
        'æ˜¯å¦æ·»åŠ åº•æ¨¡': 'æ˜¯å¦æ·»åŠ åº•æ¨¡',
        '### å¼€å§‹è®­ç»ƒ': '### å¼€å§‹è®­ç»ƒ',
        'æ‰“å¼€æ•°æ®é›†æ–‡ä»¶å¤¹': 'æ‰“å¼€æ•°æ®é›†æ–‡ä»¶å¤¹',
        'ä¸€é”®è®­ç»ƒ': 'ä¸€é”®è®­ç»ƒ',
        'å¯åŠ¨Tensorboard': 'å¯åŠ¨Tensorboard',
        '### æ¢å¤è®­ç»ƒ': '### æ¢å¤è®­ç»ƒ',
        'ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒè¿›åº¦': 'ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒè¿›åº¦',
        'åˆ·æ–°': 'åˆ·æ–°',
        'æ¢å¤è®­ç»ƒ': 'æ¢å¤è®­ç»ƒ',
        'æ¨ç†': 'æ¨ç†',
        'æ¨ç†è¯´æ˜': 'æ¨ç†è¯´æ˜',
        '### æ¨ç†å‚æ•°è®¾ç½®': '### æ¨ç†å‚æ•°è®¾ç½®',
        'å˜è°ƒ': 'å˜è°ƒ',
        'æ–‡ä»¶åˆ—è¡¨': 'æ–‡ä»¶åˆ—è¡¨',
        'é€‰æ‹©è¦å¯¼å‡ºçš„æ¨¡å‹': 'é€‰æ‹©è¦å¯¼å‡ºçš„æ¨¡å‹',
        'åˆ·æ–°æ¨¡å‹å’ŒéŸ³è‰²': 'åˆ·æ–°æ¨¡å‹å’ŒéŸ³è‰²',
        'å¯¼å‡ºæ¨¡å‹': 'å¯¼å‡ºæ¨¡å‹',
        'é€‰æ‹©éŸ³è‰²æ–‡ä»¶': 'é€‰æ‹©éŸ³è‰²æ–‡ä»¶',
        'é€‰æ‹©å¾…è½¬æ¢éŸ³é¢‘': 'é€‰æ‹©å¾…è½¬æ¢éŸ³é¢‘',
        'å¼€å§‹è½¬æ¢': 'å¼€å§‹è½¬æ¢',
        'è¾“å‡ºéŸ³é¢‘': 'è¾“å‡ºéŸ³é¢‘',
        'æ‰“å¼€æ–‡ä»¶å¤¹å¤±è´¥ï¼': 'æ‰“å¼€æ–‡ä»¶å¤¹å¤±è´¥ï¼',
        'å¼€å§‹é¢„å¤„ç†': 'å¼€å§‹é¢„å¤„ç†',
        'å¼€å§‹è®­ç»ƒ': 'å¼€å§‹è®­ç»ƒ',
        'å¼€å§‹å¯¼å‡ºæ¨¡å‹': 'å¼€å§‹å¯¼å‡ºæ¨¡å‹',
        'å¯¼å‡ºæ¨¡å‹æˆåŠŸ': 'å¯¼å‡ºæ¨¡å‹æˆåŠŸ',
        'å‡ºç°é”™è¯¯ï¼š': 'å‡ºç°é”™è¯¯ï¼š',
        'ç¼ºå°‘æ¨¡å‹æ–‡ä»¶': 'ç¼ºå°‘æ¨¡å‹æ–‡ä»¶',
        'ç¼ºå°‘æ–‡ä»¶': 'ç¼ºå°‘æ–‡ä»¶',
        'å·²æ¸…ç†æ®‹ç•™æ–‡ä»¶': 'å·²æ¸…ç†æ®‹ç•™æ–‡ä»¶',
        'æ— éœ€æ¸…ç†æ®‹ç•™æ–‡ä»¶': 'æ— éœ€æ¸…ç†æ®‹ç•™æ–‡ä»¶',
        'å¼€å§‹æ¨ç†': 'å¼€å§‹æ¨ç†',
        'æ¨ç†æˆåŠŸ': 'æ¨ç†æˆåŠŸ',
        '### 2023.7.11|[@OOPPEENN](https://github.com/OOPPEENN)ç¬¬ä¸€æ¬¡ç¼–å†™|[@thestmitsuk](https://github.com/thestmitsuki)äºŒæ¬¡è¡¥å®Œ': '### 2023.7.11|[@OOPPEENN](https://github.com/OOPPEENN)ç¬¬ä¸€æ¬¡ç¼–å†™|[@thestmitsuk](https://github.com/thestmitsuki)äºŒæ¬¡è¡¥å®Œ',
        ">=3åˆ™ä½¿ç”¨å¯¹harvestéŸ³é«˜è¯†åˆ«çš„ç»“æœä½¿ç”¨ä¸­å€¼æ»¤æ³¢ï¼Œæ•°å€¼ä¸ºæ»¤æ³¢åŠå¾„ï¼Œä½¿ç”¨å¯ä»¥å‰Šå¼±å“‘éŸ³": ">=3åˆ™ä½¿ç”¨å¯¹harvestéŸ³é«˜è¯†åˆ«çš„ç»“æœä½¿ç”¨ä¸­å€¼æ»¤æ³¢ï¼Œæ•°å€¼ä¸ºæ»¤æ³¢åŠå¾„ï¼Œä½¿ç”¨å¯ä»¥å‰Šå¼±å“‘éŸ³",
        "Aæ¨¡å‹æƒé‡": "Aæ¨¡å‹æƒé‡",
        "Aæ¨¡å‹è·¯å¾„": "Aæ¨¡å‹è·¯å¾„",
        "Bæ¨¡å‹è·¯å¾„": "Bæ¨¡å‹è·¯å¾„",
        "F0æ›²çº¿æ–‡ä»¶, å¯é€‰, ä¸€è¡Œä¸€ä¸ªéŸ³é«˜, ä»£æ›¿é»˜è®¤F0åŠå‡é™è°ƒ": "F0æ›²çº¿æ–‡ä»¶, å¯é€‰, ä¸€è¡Œä¸€ä¸ªéŸ³é«˜, ä»£æ›¿é»˜è®¤F0åŠå‡é™è°ƒ",
        "Index Rate": "Index Rate",
        "Onnxå¯¼å‡º": "Onnxå¯¼å‡º",
        "Onnxè¾“å‡ºè·¯å¾„": "Onnxè¾“å‡ºè·¯å¾„",
        "RVCæ¨¡å‹è·¯å¾„": "RVCæ¨¡å‹è·¯å¾„",
        "ckptå¤„ç†": "ckptå¤„ç†",
        "harvestè¿›ç¨‹æ•°": "harvestè¿›ç¨‹æ•°",
        "indexæ–‡ä»¶è·¯å¾„ä¸å¯åŒ…å«ä¸­æ–‡": "indexæ–‡ä»¶è·¯å¾„ä¸å¯åŒ…å«ä¸­æ–‡",
        "pthæ–‡ä»¶è·¯å¾„ä¸å¯åŒ…å«ä¸­æ–‡": "pthæ–‡ä»¶è·¯å¾„ä¸å¯åŒ…å«ä¸­æ–‡",
        "rmvpeå¡å·é…ç½®ï¼šä»¥-åˆ†éš”è¾“å…¥ä½¿ç”¨çš„ä¸åŒè¿›ç¨‹å¡å·,ä¾‹å¦‚0-0-1ä½¿ç”¨åœ¨å¡0ä¸Šè·‘2ä¸ªè¿›ç¨‹å¹¶åœ¨å¡1ä¸Šè·‘1ä¸ªè¿›ç¨‹": "rmvpeå¡å·é…ç½®ï¼šä»¥-åˆ†éš”è¾“å…¥ä½¿ç”¨çš„ä¸åŒè¿›ç¨‹å¡å·,ä¾‹å¦‚0-0-1ä½¿ç”¨åœ¨å¡0ä¸Šè·‘2ä¸ªè¿›ç¨‹å¹¶åœ¨å¡1ä¸Šè·‘1ä¸ªè¿›ç¨‹",
        "step1: å¡«å†™å®éªŒé…ç½®. å®éªŒæ•°æ®æ”¾åœ¨logsä¸‹, æ¯ä¸ªå®éªŒä¸€ä¸ªæ–‡ä»¶å¤¹, éœ€æ‰‹å·¥è¾“å…¥å®éªŒåè·¯å¾„, å†…å«å®éªŒé…ç½®, æ—¥å¿—, è®­ç»ƒå¾—åˆ°çš„æ¨¡å‹æ–‡ä»¶. ": "step1: å¡«å†™å®éªŒé…ç½®. å®éªŒæ•°æ®æ”¾åœ¨logsä¸‹, æ¯ä¸ªå®éªŒä¸€ä¸ªæ–‡ä»¶å¤¹, éœ€æ‰‹å·¥è¾“å…¥å®éªŒåè·¯å¾„, å†…å«å®éªŒé…ç½®, æ—¥å¿—, è®­ç»ƒå¾—åˆ°çš„æ¨¡å‹æ–‡ä»¶. ",
        "step1:æ­£åœ¨å¤„ç†æ•°æ®": "step1:æ­£åœ¨å¤„ç†æ•°æ®",
        "step2:æ­£åœ¨æå–éŸ³é«˜&æ­£åœ¨æå–ç‰¹å¾": "step2:æ­£åœ¨æå–éŸ³é«˜&æ­£åœ¨æå–ç‰¹å¾",
        "step2a: è‡ªåŠ¨éå†è®­ç»ƒæ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰å¯è§£ç æˆéŸ³é¢‘çš„æ–‡ä»¶å¹¶è¿›è¡Œåˆ‡ç‰‡å½’ä¸€åŒ–, åœ¨å®éªŒç›®å½•ä¸‹ç”Ÿæˆ2ä¸ªwavæ–‡ä»¶å¤¹; æš‚æ—¶åªæ”¯æŒå•äººè®­ç»ƒ. ": "step2a: è‡ªåŠ¨éå†è®­ç»ƒæ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰å¯è§£ç æˆéŸ³é¢‘çš„æ–‡ä»¶å¹¶è¿›è¡Œåˆ‡ç‰‡å½’ä¸€åŒ–, åœ¨å®éªŒç›®å½•ä¸‹ç”Ÿæˆ2ä¸ªwavæ–‡ä»¶å¤¹; æš‚æ—¶åªæ”¯æŒå•äººè®­ç»ƒ. ",
        "step2b: ä½¿ç”¨CPUæå–éŸ³é«˜(å¦‚æœæ¨¡å‹å¸¦éŸ³é«˜), ä½¿ç”¨GPUæå–ç‰¹å¾(é€‰æ‹©å¡å·)": "step2b: ä½¿ç”¨CPUæå–éŸ³é«˜(å¦‚æœæ¨¡å‹å¸¦éŸ³é«˜), ä½¿ç”¨GPUæå–ç‰¹å¾(é€‰æ‹©å¡å·)",
        "step3: å¡«å†™è®­ç»ƒè®¾ç½®, å¼€å§‹è®­ç»ƒæ¨¡å‹å’Œç´¢å¼•": "step3: å¡«å†™è®­ç»ƒè®¾ç½®, å¼€å§‹è®­ç»ƒæ¨¡å‹å’Œç´¢å¼•",
        "step3a:æ­£åœ¨è®­ç»ƒæ¨¡å‹": "step3a:æ­£åœ¨è®­ç»ƒæ¨¡å‹",
        "ä¸€é”®è®­ç»ƒ": "ä¸€é”®è®­ç»ƒ",
        "ä¹Ÿå¯æ‰¹é‡è¾“å…¥éŸ³é¢‘æ–‡ä»¶, äºŒé€‰ä¸€, ä¼˜å…ˆè¯»æ–‡ä»¶å¤¹": "ä¹Ÿå¯æ‰¹é‡è¾“å…¥éŸ³é¢‘æ–‡ä»¶, äºŒé€‰ä¸€, ä¼˜å…ˆè¯»æ–‡ä»¶å¤¹",
        "äººå£°ä¼´å¥åˆ†ç¦»æ‰¹é‡å¤„ç†ï¼Œ ä½¿ç”¨UVR5æ¨¡å‹ã€‚ <br>åˆæ ¼çš„æ–‡ä»¶å¤¹è·¯å¾„æ ¼å¼ä¸¾ä¾‹ï¼š E:\\codes\\py39\\vits_vc_gpu\\ç™½é¹­éœœåæµ‹è¯•æ ·ä¾‹(å»æ–‡ä»¶ç®¡ç†å™¨åœ°å€æ æ‹·å°±è¡Œäº†)ã€‚ <br>æ¨¡å‹åˆ†ä¸ºä¸‰ç±»ï¼š <br>1ã€ä¿ç•™äººå£°ï¼šä¸å¸¦å’Œå£°çš„éŸ³é¢‘é€‰è¿™ä¸ªï¼Œå¯¹ä¸»äººå£°ä¿ç•™æ¯”HP5æ›´å¥½ã€‚å†…ç½®HP2å’ŒHP3ä¸¤ä¸ªæ¨¡å‹ï¼ŒHP3å¯èƒ½è½»å¾®æ¼ä¼´å¥ä½†å¯¹ä¸»äººå£°ä¿ç•™æ¯”HP2ç¨å¾®å¥½ä¸€ä¸ç‚¹ï¼› <br>2ã€ä»…ä¿ç•™ä¸»äººå£°ï¼šå¸¦å’Œå£°çš„éŸ³é¢‘é€‰è¿™ä¸ªï¼Œå¯¹ä¸»äººå£°å¯èƒ½æœ‰å‰Šå¼±ã€‚å†…ç½®HP5ä¸€ä¸ªæ¨¡å‹ï¼› <br> 3ã€å»æ··å“ã€å»å»¶è¿Ÿæ¨¡å‹ï¼ˆby FoxJoyï¼‰ï¼š<br>â€ƒâ€ƒ(1)MDX-Net(onnx_dereverb):å¯¹äºåŒé€šé“æ··å“æ˜¯æœ€å¥½çš„é€‰æ‹©ï¼Œä¸èƒ½å»é™¤å•é€šé“æ··å“ï¼›<br>&emsp;(234)DeEcho:å»é™¤å»¶è¿Ÿæ•ˆæœã€‚Aggressiveæ¯”Normalå»é™¤å¾—æ›´å½»åº•ï¼ŒDeReverbé¢å¤–å»é™¤æ··å“ï¼Œå¯å»é™¤å•å£°é“æ··å“ï¼Œä½†æ˜¯å¯¹é«˜é¢‘é‡çš„æ¿å¼æ··å“å»ä¸å¹²å‡€ã€‚<br>å»æ··å“/å»å»¶è¿Ÿï¼Œé™„ï¼š<br>1ã€DeEcho-DeReverbæ¨¡å‹çš„è€—æ—¶æ˜¯å¦å¤–2ä¸ªDeEchoæ¨¡å‹çš„æ¥è¿‘2å€ï¼›<br>2ã€MDX-Net-Dereverbæ¨¡å‹æŒºæ…¢çš„ï¼›<br>3ã€ä¸ªäººæ¨èçš„æœ€å¹²å‡€çš„é…ç½®æ˜¯å…ˆMDX-Netå†DeEcho-Aggressiveã€‚": "äººå£°ä¼´å¥åˆ†ç¦»æ‰¹é‡å¤„ç†ï¼Œ ä½¿ç”¨UVR5æ¨¡å‹ã€‚ <br>åˆæ ¼çš„æ–‡ä»¶å¤¹è·¯å¾„æ ¼å¼ä¸¾ä¾‹ï¼š E:\\codes\\py39\\vits_vc_gpu\\ç™½é¹­éœœåæµ‹è¯•æ ·ä¾‹(å»æ–‡ä»¶ç®¡ç†å™¨åœ°å€æ æ‹·å°±è¡Œäº†)ã€‚ <br>æ¨¡å‹åˆ†ä¸ºä¸‰ç±»ï¼š <br>1ã€ä¿ç•™äººå£°ï¼šä¸å¸¦å’Œå£°çš„éŸ³é¢‘é€‰è¿™ä¸ªï¼Œå¯¹ä¸»äººå£°ä¿ç•™æ¯”HP5æ›´å¥½ã€‚å†…ç½®HP2å’ŒHP3ä¸¤ä¸ªæ¨¡å‹ï¼ŒHP3å¯èƒ½è½»å¾®æ¼ä¼´å¥ä½†å¯¹ä¸»äººå£°ä¿ç•™æ¯”HP2ç¨å¾®å¥½ä¸€ä¸ç‚¹ï¼› <br>2ã€ä»…ä¿ç•™ä¸»äººå£°ï¼šå¸¦å’Œå£°çš„éŸ³é¢‘é€‰è¿™ä¸ªï¼Œå¯¹ä¸»äººå£°å¯èƒ½æœ‰å‰Šå¼±ã€‚å†…ç½®HP5ä¸€ä¸ªæ¨¡å‹ï¼› <br> 3ã€å»æ··å“ã€å»å»¶è¿Ÿæ¨¡å‹ï¼ˆby FoxJoyï¼‰ï¼š<br>â€ƒâ€ƒ(1)MDX-Net(onnx_dereverb):å¯¹äºåŒé€šé“æ··å“æ˜¯æœ€å¥½çš„é€‰æ‹©ï¼Œä¸èƒ½å»é™¤å•é€šé“æ··å“ï¼›<br>&emsp;(234)DeEcho:å»é™¤å»¶è¿Ÿæ•ˆæœã€‚Aggressiveæ¯”Normalå»é™¤å¾—æ›´å½»åº•ï¼ŒDeReverbé¢å¤–å»é™¤æ··å“ï¼Œå¯å»é™¤å•å£°é“æ··å“ï¼Œä½†æ˜¯å¯¹é«˜é¢‘é‡çš„æ¿å¼æ··å“å»ä¸å¹²å‡€ã€‚<br>å»æ··å“/å»å»¶è¿Ÿï¼Œé™„ï¼š<br>1ã€DeEcho-DeReverbæ¨¡å‹çš„è€—æ—¶æ˜¯å¦å¤–2ä¸ªDeEchoæ¨¡å‹çš„æ¥è¿‘2å€ï¼›<br>2ã€MDX-Net-Dereverbæ¨¡å‹æŒºæ…¢çš„ï¼›<br>3ã€ä¸ªäººæ¨èçš„æœ€å¹²å‡€çš„é…ç½®æ˜¯å…ˆMDX-Netå†DeEcho-Aggressiveã€‚",
        "ä»¥-åˆ†éš”è¾“å…¥ä½¿ç”¨çš„å¡å·, ä¾‹å¦‚   0-1-2   ä½¿ç”¨å¡0å’Œå¡1å’Œå¡2": "ä»¥-åˆ†éš”è¾“å…¥ä½¿ç”¨çš„å¡å·, ä¾‹å¦‚   0-1-2   ä½¿ç”¨å¡0å’Œå¡1å’Œå¡2",
        "ä¼´å¥äººå£°åˆ†ç¦»&å»æ··å“&å»å›å£°": "ä¼´å¥äººå£°åˆ†ç¦»&å»æ··å“&å»å›å£°",
        "ä¿å­˜å": "ä¿å­˜å",
        "ä¿å­˜çš„æ–‡ä»¶å, é»˜è®¤ç©ºä¸ºå’Œæºæ–‡ä»¶åŒå": "ä¿å­˜çš„æ–‡ä»¶å, é»˜è®¤ç©ºä¸ºå’Œæºæ–‡ä»¶åŒå",
        "ä¿å­˜çš„æ¨¡å‹åä¸å¸¦åç¼€": "ä¿å­˜çš„æ¨¡å‹åä¸å¸¦åç¼€",
        "ä¿å­˜é¢‘ç‡save_every_epoch": "ä¿å­˜é¢‘ç‡save_every_epoch",
        "ä¿æŠ¤æ¸…è¾…éŸ³å’Œå‘¼å¸å£°ï¼Œé˜²æ­¢ç”µéŸ³æ’•è£‚ç­‰artifactï¼Œæ‹‰æ»¡0.5ä¸å¼€å¯ï¼Œè°ƒä½åŠ å¤§ä¿æŠ¤åŠ›åº¦ä½†å¯èƒ½é™ä½ç´¢å¼•æ•ˆæœ": "ä¿æŠ¤æ¸…è¾…éŸ³å’Œå‘¼å¸å£°ï¼Œé˜²æ­¢ç”µéŸ³æ’•è£‚ç­‰artifactï¼Œæ‹‰æ»¡0.5ä¸å¼€å¯ï¼Œè°ƒä½åŠ å¤§ä¿æŠ¤åŠ›åº¦ä½†å¯èƒ½é™ä½ç´¢å¼•æ•ˆæœ",
        "ä¿®æ”¹": "ä¿®æ”¹",
        "ä¿®æ”¹æ¨¡å‹ä¿¡æ¯(ä»…æ”¯æŒweightsæ–‡ä»¶å¤¹ä¸‹æå–çš„å°æ¨¡å‹æ–‡ä»¶)": "ä¿®æ”¹æ¨¡å‹ä¿¡æ¯(ä»…æ”¯æŒweightsæ–‡ä»¶å¤¹ä¸‹æå–çš„å°æ¨¡å‹æ–‡ä»¶)",
        "åœæ­¢éŸ³é¢‘è½¬æ¢": "åœæ­¢éŸ³é¢‘è½¬æ¢",
        "å…¨æµç¨‹ç»“æŸï¼": "å…¨æµç¨‹ç»“æŸï¼",
        "åˆ·æ–°éŸ³è‰²åˆ—è¡¨å’Œç´¢å¼•è·¯å¾„": "åˆ·æ–°éŸ³è‰²åˆ—è¡¨å’Œç´¢å¼•è·¯å¾„",
        "åŠ è½½æ¨¡å‹": "åŠ è½½æ¨¡å‹",
        "åŠ è½½é¢„è®­ç»ƒåº•æ¨¡Dè·¯å¾„": "åŠ è½½é¢„è®­ç»ƒåº•æ¨¡Dè·¯å¾„",
        "åŠ è½½é¢„è®­ç»ƒåº•æ¨¡Gè·¯å¾„": "åŠ è½½é¢„è®­ç»ƒåº•æ¨¡Gè·¯å¾„",
        "å•æ¬¡æ¨ç†": "å•æ¬¡æ¨ç†",
        "å¸è½½éŸ³è‰²çœæ˜¾å­˜": "å¸è½½éŸ³è‰²çœæ˜¾å­˜",
        "å˜è°ƒ(æ•´æ•°, åŠéŸ³æ•°é‡, å‡å…«åº¦12é™å…«åº¦-12)": "å˜è°ƒ(æ•´æ•°, åŠéŸ³æ•°é‡, å‡å…«åº¦12é™å…«åº¦-12)",
        "åå¤„ç†é‡é‡‡æ ·è‡³æœ€ç»ˆé‡‡æ ·ç‡ï¼Œ0ä¸ºä¸è¿›è¡Œé‡é‡‡æ ·": "åå¤„ç†é‡é‡‡æ ·è‡³æœ€ç»ˆé‡‡æ ·ç‡ï¼Œ0ä¸ºä¸è¿›è¡Œé‡é‡‡æ ·",
        "å¦": "å¦",
        "å“åº”é˜ˆå€¼": "å“åº”é˜ˆå€¼",
        "å“åº¦å› å­": "å“åº¦å› å­",
        "å¤„ç†æ•°æ®": "å¤„ç†æ•°æ®",
        "å¯¼å‡ºOnnxæ¨¡å‹": "å¯¼å‡ºOnnxæ¨¡å‹",
        "å¯¼å‡ºæ–‡ä»¶æ ¼å¼": "å¯¼å‡ºæ–‡ä»¶æ ¼å¼",
        "å¸¸è§é—®é¢˜è§£ç­”": "å¸¸è§é—®é¢˜è§£ç­”",
        "å¸¸è§„è®¾ç½®": "å¸¸è§„è®¾ç½®",
        "å¼€å§‹éŸ³é¢‘è½¬æ¢": "å¼€å§‹éŸ³é¢‘è½¬æ¢",
        "å¾ˆé—æ†¾æ‚¨è¿™æ²¡æœ‰èƒ½ç”¨çš„æ˜¾å¡æ¥æ”¯æŒæ‚¨è®­ç»ƒ": "å¾ˆé—æ†¾æ‚¨è¿™æ²¡æœ‰èƒ½ç”¨çš„æ˜¾å¡æ¥æ”¯æŒæ‚¨è®­ç»ƒ",
        "æ€§èƒ½è®¾ç½®": "æ€§èƒ½è®¾ç½®",
        "æ€»è®­ç»ƒè½®æ•°total_epoch": "æ€»è®­ç»ƒè½®æ•°total_epoch",
        "æ‰¹é‡æ¨ç†": "æ‰¹é‡æ¨ç†",
        "æ‰¹é‡è½¬æ¢, è¾“å…¥å¾…è½¬æ¢éŸ³é¢‘æ–‡ä»¶å¤¹, æˆ–ä¸Šä¼ å¤šä¸ªéŸ³é¢‘æ–‡ä»¶, åœ¨æŒ‡å®šæ–‡ä»¶å¤¹(é»˜è®¤opt)ä¸‹è¾“å‡ºè½¬æ¢çš„éŸ³é¢‘. ": "æ‰¹é‡è½¬æ¢, è¾“å…¥å¾…è½¬æ¢éŸ³é¢‘æ–‡ä»¶å¤¹, æˆ–ä¸Šä¼ å¤šä¸ªéŸ³é¢‘æ–‡ä»¶, åœ¨æŒ‡å®šæ–‡ä»¶å¤¹(é»˜è®¤opt)ä¸‹è¾“å‡ºè½¬æ¢çš„éŸ³é¢‘. ",
        "æŒ‡å®šè¾“å‡ºä¸»äººå£°æ–‡ä»¶å¤¹": "æŒ‡å®šè¾“å‡ºä¸»äººå£°æ–‡ä»¶å¤¹",
        "æŒ‡å®šè¾“å‡ºæ–‡ä»¶å¤¹": "æŒ‡å®šè¾“å‡ºæ–‡ä»¶å¤¹",
        "æŒ‡å®šè¾“å‡ºéä¸»äººå£°æ–‡ä»¶å¤¹": "æŒ‡å®šè¾“å‡ºéä¸»äººå£°æ–‡ä»¶å¤¹",
        "æ¨ç†æ—¶é—´(ms):": "æ¨ç†æ—¶é—´(ms):",
        "æ¨ç†éŸ³è‰²": "æ¨ç†éŸ³è‰²",
        "æå–": "æå–",
        "æå–éŸ³é«˜å’Œå¤„ç†æ•°æ®ä½¿ç”¨çš„CPUè¿›ç¨‹æ•°": "æå–éŸ³é«˜å’Œå¤„ç†æ•°æ®ä½¿ç”¨çš„CPUè¿›ç¨‹æ•°",
        "æ˜¯": "æ˜¯",
        "æ˜¯å¦ä»…ä¿å­˜æœ€æ–°çš„ckptæ–‡ä»¶ä»¥èŠ‚çœç¡¬ç›˜ç©ºé—´": "æ˜¯å¦ä»…ä¿å­˜æœ€æ–°çš„ckptæ–‡ä»¶ä»¥èŠ‚çœç¡¬ç›˜ç©ºé—´",
        "æ˜¯å¦åœ¨æ¯æ¬¡ä¿å­˜æ—¶é—´ç‚¹å°†æœ€ç»ˆå°æ¨¡å‹ä¿å­˜è‡³weightsæ–‡ä»¶å¤¹": "æ˜¯å¦åœ¨æ¯æ¬¡ä¿å­˜æ—¶é—´ç‚¹å°†æœ€ç»ˆå°æ¨¡å‹ä¿å­˜è‡³weightsæ–‡ä»¶å¤¹",
        "æ˜¯å¦ç¼“å­˜æ‰€æœ‰è®­ç»ƒé›†è‡³æ˜¾å­˜. 10minä»¥ä¸‹å°æ•°æ®å¯ç¼“å­˜ä»¥åŠ é€Ÿè®­ç»ƒ, å¤§æ•°æ®ç¼“å­˜ä¼šç‚¸æ˜¾å­˜ä¹ŸåŠ ä¸äº†å¤šå°‘é€Ÿ": "æ˜¯å¦ç¼“å­˜æ‰€æœ‰è®­ç»ƒé›†è‡³æ˜¾å­˜. 10minä»¥ä¸‹å°æ•°æ®å¯ç¼“å­˜ä»¥åŠ é€Ÿè®­ç»ƒ, å¤§æ•°æ®ç¼“å­˜ä¼šç‚¸æ˜¾å­˜ä¹ŸåŠ ä¸äº†å¤šå°‘é€Ÿ",
        "æ˜¾å¡ä¿¡æ¯": "æ˜¾å¡ä¿¡æ¯",
        "æœ¬è½¯ä»¶ä»¥MITåè®®å¼€æº, ä½œè€…ä¸å¯¹è½¯ä»¶å…·å¤‡ä»»ä½•æ§åˆ¶åŠ›, ä½¿ç”¨è½¯ä»¶è€…ã€ä¼ æ’­è½¯ä»¶å¯¼å‡ºçš„å£°éŸ³è€…è‡ªè´Ÿå…¨è´£. <br>å¦‚ä¸è®¤å¯è¯¥æ¡æ¬¾, åˆ™ä¸èƒ½ä½¿ç”¨æˆ–å¼•ç”¨è½¯ä»¶åŒ…å†…ä»»ä½•ä»£ç å’Œæ–‡ä»¶. è¯¦è§æ ¹ç›®å½•<b>LICENSE</b>.": "æœ¬è½¯ä»¶ä»¥MITåè®®å¼€æº, ä½œè€…ä¸å¯¹è½¯ä»¶å…·å¤‡ä»»ä½•æ§åˆ¶åŠ›, ä½¿ç”¨è½¯ä»¶è€…ã€ä¼ æ’­è½¯ä»¶å¯¼å‡ºçš„å£°éŸ³è€…è‡ªè´Ÿå…¨è´£. <br>å¦‚ä¸è®¤å¯è¯¥æ¡æ¬¾, åˆ™ä¸èƒ½ä½¿ç”¨æˆ–å¼•ç”¨è½¯ä»¶åŒ…å†…ä»»ä½•ä»£ç å’Œæ–‡ä»¶. è¯¦è§æ ¹ç›®å½•<b>LICENSE</b>.",
        "æŸ¥çœ‹": "æŸ¥çœ‹",
        "æŸ¥çœ‹æ¨¡å‹ä¿¡æ¯(ä»…æ”¯æŒweightsæ–‡ä»¶å¤¹ä¸‹æå–çš„å°æ¨¡å‹æ–‡ä»¶)": "æŸ¥çœ‹æ¨¡å‹ä¿¡æ¯(ä»…æ”¯æŒweightsæ–‡ä»¶å¤¹ä¸‹æå–çš„å°æ¨¡å‹æ–‡ä»¶)",
        "æ£€ç´¢ç‰¹å¾å æ¯”": "æ£€ç´¢ç‰¹å¾å æ¯”",
        "æ¨¡å‹": "æ¨¡å‹",
        "æ¨¡å‹æ¨ç†": "æ¨¡å‹æ¨ç†",
        "æ¨¡å‹æå–(è¾“å…¥logsæ–‡ä»¶å¤¹ä¸‹å¤§æ–‡ä»¶æ¨¡å‹è·¯å¾„),é€‚ç”¨äºè®­ä¸€åŠä¸æƒ³è®­äº†æ¨¡å‹æ²¡æœ‰è‡ªåŠ¨æå–ä¿å­˜å°æ–‡ä»¶æ¨¡å‹,æˆ–è€…æƒ³æµ‹è¯•ä¸­é—´æ¨¡å‹çš„æƒ…å†µ": "æ¨¡å‹æå–(è¾“å…¥logsæ–‡ä»¶å¤¹ä¸‹å¤§æ–‡ä»¶æ¨¡å‹è·¯å¾„),é€‚ç”¨äºè®­ä¸€åŠä¸æƒ³è®­äº†æ¨¡å‹æ²¡æœ‰è‡ªåŠ¨æå–ä¿å­˜å°æ–‡ä»¶æ¨¡å‹,æˆ–è€…æƒ³æµ‹è¯•ä¸­é—´æ¨¡å‹çš„æƒ…å†µ",
        "æ¨¡å‹æ˜¯å¦å¸¦éŸ³é«˜æŒ‡å¯¼": "æ¨¡å‹æ˜¯å¦å¸¦éŸ³é«˜æŒ‡å¯¼",
        "æ¨¡å‹æ˜¯å¦å¸¦éŸ³é«˜æŒ‡å¯¼(å”±æ­Œä¸€å®šè¦, è¯­éŸ³å¯ä»¥ä¸è¦)": "æ¨¡å‹æ˜¯å¦å¸¦éŸ³é«˜æŒ‡å¯¼(å”±æ­Œä¸€å®šè¦, è¯­éŸ³å¯ä»¥ä¸è¦)",
        "æ¨¡å‹æ˜¯å¦å¸¦éŸ³é«˜æŒ‡å¯¼,1æ˜¯0å¦": "æ¨¡å‹æ˜¯å¦å¸¦éŸ³é«˜æŒ‡å¯¼,1æ˜¯0å¦",
        "æ¨¡å‹ç‰ˆæœ¬å‹å·": "æ¨¡å‹ç‰ˆæœ¬å‹å·",
        "æ¨¡å‹èåˆ, å¯ç”¨äºæµ‹è¯•éŸ³è‰²èåˆ": "æ¨¡å‹èåˆ, å¯ç”¨äºæµ‹è¯•éŸ³è‰²èåˆ",
        "æ¨¡å‹è·¯å¾„": "æ¨¡å‹è·¯å¾„",
        "æ¯å¼ æ˜¾å¡çš„batch_size": "æ¯å¼ æ˜¾å¡çš„batch_size",
        "æ·¡å…¥æ·¡å‡ºé•¿åº¦": "æ·¡å…¥æ·¡å‡ºé•¿åº¦",
        "ç‰ˆæœ¬": "ç‰ˆæœ¬",
        "ç‰¹å¾æå–": "ç‰¹å¾æå–",
        "ç‰¹å¾æ£€ç´¢åº“æ–‡ä»¶è·¯å¾„,ä¸ºç©ºåˆ™ä½¿ç”¨ä¸‹æ‹‰çš„é€‰æ‹©ç»“æœ": "ç‰¹å¾æ£€ç´¢åº“æ–‡ä»¶è·¯å¾„,ä¸ºç©ºåˆ™ä½¿ç”¨ä¸‹æ‹‰çš„é€‰æ‹©ç»“æœ",
        "ç”·è½¬å¥³æ¨è+12key, å¥³è½¬ç”·æ¨è-12key, å¦‚æœéŸ³åŸŸçˆ†ç‚¸å¯¼è‡´éŸ³è‰²å¤±çœŸä¹Ÿå¯ä»¥è‡ªå·±è°ƒæ•´åˆ°åˆé€‚éŸ³åŸŸ. ": "ç”·è½¬å¥³æ¨è+12key, å¥³è½¬ç”·æ¨è-12key, å¦‚æœéŸ³åŸŸçˆ†ç‚¸å¯¼è‡´éŸ³è‰²å¤±çœŸä¹Ÿå¯ä»¥è‡ªå·±è°ƒæ•´åˆ°åˆé€‚éŸ³åŸŸ. ",
        "ç›®æ ‡é‡‡æ ·ç‡": "ç›®æ ‡é‡‡æ ·ç‡",
        "ç®—æ³•å»¶è¿Ÿ(ms):": "ç®—æ³•å»¶è¿Ÿ(ms):",
        "è‡ªåŠ¨æ£€æµ‹indexè·¯å¾„,ä¸‹æ‹‰å¼é€‰æ‹©(dropdown)": "è‡ªåŠ¨æ£€æµ‹indexè·¯å¾„,ä¸‹æ‹‰å¼é€‰æ‹©(dropdown)",
        "èåˆ": "èåˆ",
        "è¦æ”¹çš„æ¨¡å‹ä¿¡æ¯": "è¦æ”¹çš„æ¨¡å‹ä¿¡æ¯",
        "è¦ç½®å…¥çš„æ¨¡å‹ä¿¡æ¯": "è¦ç½®å…¥çš„æ¨¡å‹ä¿¡æ¯",
        "è®­ç»ƒ": "è®­ç»ƒ",
        "è®­ç»ƒæ¨¡å‹": "è®­ç»ƒæ¨¡å‹",
        "è®­ç»ƒç‰¹å¾ç´¢å¼•": "è®­ç»ƒç‰¹å¾ç´¢å¼•",
        "è®­ç»ƒç»“æŸ, æ‚¨å¯æŸ¥çœ‹æ§åˆ¶å°è®­ç»ƒæ—¥å¿—æˆ–å®éªŒæ–‡ä»¶å¤¹ä¸‹çš„train.log": "è®­ç»ƒç»“æŸ, æ‚¨å¯æŸ¥çœ‹æ§åˆ¶å°è®­ç»ƒæ—¥å¿—æˆ–å®éªŒæ–‡ä»¶å¤¹ä¸‹çš„train.log",
        "è¯·æŒ‡å®šè¯´è¯äººid": "è¯·æŒ‡å®šè¯´è¯äººid",
        "è¯·é€‰æ‹©indexæ–‡ä»¶": "è¯·é€‰æ‹©indexæ–‡ä»¶",
        "è¯·é€‰æ‹©pthæ–‡ä»¶": "è¯·é€‰æ‹©pthæ–‡ä»¶",
        "è¯·é€‰æ‹©è¯´è¯äººid": "è¯·é€‰æ‹©è¯´è¯äººid",
        "è½¬æ¢": "è½¬æ¢",
        "è¾“å…¥å®éªŒå": "è¾“å…¥å®éªŒå",
        "è¾“å…¥å¾…å¤„ç†éŸ³é¢‘æ–‡ä»¶å¤¹è·¯å¾„": "è¾“å…¥å¾…å¤„ç†éŸ³é¢‘æ–‡ä»¶å¤¹è·¯å¾„",
        "è¾“å…¥å¾…å¤„ç†éŸ³é¢‘æ–‡ä»¶å¤¹è·¯å¾„(å»æ–‡ä»¶ç®¡ç†å™¨åœ°å€æ æ‹·å°±è¡Œäº†)": "è¾“å…¥å¾…å¤„ç†éŸ³é¢‘æ–‡ä»¶å¤¹è·¯å¾„(å»æ–‡ä»¶ç®¡ç†å™¨åœ°å€æ æ‹·å°±è¡Œäº†)",
        "è¾“å…¥å¾…å¤„ç†éŸ³é¢‘æ–‡ä»¶è·¯å¾„(é»˜è®¤æ˜¯æ­£ç¡®æ ¼å¼ç¤ºä¾‹)": "è¾“å…¥å¾…å¤„ç†éŸ³é¢‘æ–‡ä»¶è·¯å¾„(é»˜è®¤æ˜¯æ­£ç¡®æ ¼å¼ç¤ºä¾‹)",
        "è¾“å…¥æºéŸ³é‡åŒ…ç»œæ›¿æ¢è¾“å‡ºéŸ³é‡åŒ…ç»œèåˆæ¯”ä¾‹ï¼Œè¶Šé è¿‘1è¶Šä½¿ç”¨è¾“å‡ºåŒ…ç»œ": "è¾“å…¥æºéŸ³é‡åŒ…ç»œæ›¿æ¢è¾“å‡ºéŸ³é‡åŒ…ç»œèåˆæ¯”ä¾‹ï¼Œè¶Šé è¿‘1è¶Šä½¿ç”¨è¾“å‡ºåŒ…ç»œ",
        "è¾“å…¥ç›‘å¬": "è¾“å…¥ç›‘å¬",
        "è¾“å…¥è®­ç»ƒæ–‡ä»¶å¤¹è·¯å¾„": "è¾“å…¥è®­ç»ƒæ–‡ä»¶å¤¹è·¯å¾„",
        "è¾“å…¥è®¾å¤‡": "è¾“å…¥è®¾å¤‡",
        "è¾“å…¥é™å™ª": "è¾“å…¥é™å™ª",
        "è¾“å‡ºä¿¡æ¯": "è¾“å‡ºä¿¡æ¯",
        "è¾“å‡ºå˜å£°": "è¾“å‡ºå˜å£°",
        "è¾“å‡ºè®¾å¤‡": "è¾“å‡ºè®¾å¤‡",
        "è¾“å‡ºé™å™ª": "è¾“å‡ºé™å™ª",
        "è¾“å‡ºéŸ³é¢‘(å³ä¸‹è§’ä¸‰ä¸ªç‚¹,ç‚¹äº†å¯ä»¥ä¸‹è½½)": "è¾“å‡ºéŸ³é¢‘(å³ä¸‹è§’ä¸‰ä¸ªç‚¹,ç‚¹äº†å¯ä»¥ä¸‹è½½)",
        "é€‰æ‹©.indexæ–‡ä»¶": "é€‰æ‹©.indexæ–‡ä»¶",
        "é€‰æ‹©.pthæ–‡ä»¶": "é€‰æ‹©.pthæ–‡ä»¶",
        "é€‰æ‹©éŸ³é«˜æå–ç®—æ³•,è¾“å…¥æ­Œå£°å¯ç”¨pmæé€Ÿ,harvestä½éŸ³å¥½ä½†å·¨æ…¢æ— æ¯”,crepeæ•ˆæœå¥½ä½†åƒGPU": "é€‰æ‹©éŸ³é«˜æå–ç®—æ³•,è¾“å…¥æ­Œå£°å¯ç”¨pmæé€Ÿ,harvestä½éŸ³å¥½ä½†å·¨æ…¢æ— æ¯”,crepeæ•ˆæœå¥½ä½†åƒGPU",
        "é€‰æ‹©éŸ³é«˜æå–ç®—æ³•,è¾“å…¥æ­Œå£°å¯ç”¨pmæé€Ÿ,harvestä½éŸ³å¥½ä½†å·¨æ…¢æ— æ¯”,crepeæ•ˆæœå¥½ä½†åƒGPU,rmvpeæ•ˆæœæœ€å¥½ä¸”å¾®åƒGPU": "é€‰æ‹©éŸ³é«˜æå–ç®—æ³•,è¾“å…¥æ­Œå£°å¯ç”¨pmæé€Ÿ,harvestä½éŸ³å¥½ä½†å·¨æ…¢æ— æ¯”,crepeæ•ˆæœå¥½ä½†åƒGPU,rmvpeæ•ˆæœæœ€å¥½ä¸”å¾®åƒGPU",
        "é€‰æ‹©éŸ³é«˜æå–ç®—æ³•:è¾“å…¥æ­Œå£°å¯ç”¨pmæé€Ÿ,é«˜è´¨é‡è¯­éŸ³ä½†CPUå·®å¯ç”¨dioæé€Ÿ,harvestè´¨é‡æ›´å¥½ä½†æ…¢,rmvpeæ•ˆæœæœ€å¥½ä¸”å¾®åƒCPU/GPU": "é€‰æ‹©éŸ³é«˜æå–ç®—æ³•:è¾“å…¥æ­Œå£°å¯ç”¨pmæé€Ÿ,é«˜è´¨é‡è¯­éŸ³ä½†CPUå·®å¯ç”¨dioæé€Ÿ,harvestè´¨é‡æ›´å¥½ä½†æ…¢,rmvpeæ•ˆæœæœ€å¥½ä¸”å¾®åƒCPU/GPU",
        "é‡‡æ ·é•¿åº¦": "é‡‡æ ·é•¿åº¦",
        "é‡è½½è®¾å¤‡åˆ—è¡¨": "é‡è½½è®¾å¤‡åˆ—è¡¨",
        "éŸ³è°ƒè®¾ç½®": "éŸ³è°ƒè®¾ç½®",
        "éŸ³é¢‘è®¾å¤‡(è¯·ä½¿ç”¨åŒç§ç±»é©±åŠ¨)": "éŸ³é¢‘è®¾å¤‡(è¯·ä½¿ç”¨åŒç§ç±»é©±åŠ¨)",
        "éŸ³é«˜ç®—æ³•": "éŸ³é«˜ç®—æ³•",
        "é¢å¤–æ¨ç†æ—¶é•¿": "é¢å¤–æ¨ç†æ—¶é•¿"
        },
    'en_US': {
        'SUPER': 'zh_CN',
        'LANGUAGE': 'en_US',
        'åˆå§‹åŒ–æˆåŠŸ': 'Initialization successful',
        'å°±ç»ª': 'Ready',
        'é¢„å¤„ç†-è®­ç»ƒ': 'Preprocessing-Training',
        'è®­ç»ƒè¯´æ˜': 'Training instructions',
        '### é¢„å¤„ç†å‚æ•°è®¾ç½®': '### Preprocessing parameter settings',
        'æ¨¡å‹åç§°': 'Model name',
        'f0æå–å™¨': 'f0 extractor',
        'é¢„å¤„ç†çº¿ç¨‹æ•°': 'Preprocessing thread number',
        '### è®­ç»ƒå‚æ•°è®¾ç½®': '### Training parameter settings',
        'å­¦ä¹ ç‡': 'Learning rate',
        'æ‰¹å¤§å°': 'Batch size',
        'è®­ç»ƒæ—¥å¿—è®°å½•é—´éš”ï¼ˆstepï¼‰': 'Training log recording interval (step)',
        'éªŒè¯é›†éªŒè¯é—´éš”ï¼ˆepochï¼‰': 'Validation set validation interval (epoch)',
        'æ£€æŸ¥ç‚¹ä¿å­˜é—´éš”ï¼ˆepochï¼‰': 'Checkpoint save interval (epoch)',
        'ä¿ç•™æœ€æ–°çš„æ£€æŸ¥ç‚¹æ–‡ä»¶(0ä¿å­˜å…¨éƒ¨)': 'Keep the latest checkpoint file (0 save all)',
        'æ˜¯å¦æ·»åŠ åº•æ¨¡': 'Whether to add the base model',
        '### å¼€å§‹è®­ç»ƒ': '### Start training',
        'æ‰“å¼€æ•°æ®é›†æ–‡ä»¶å¤¹': 'Open the dataset folder',
        'å¯åŠ¨Tensorboard': 'Start Tensorboard',
        '### æ¢å¤è®­ç»ƒ': '### Resume training',
        'ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒè¿›åº¦': 'Restore training progress from checkpoint',
        'åˆ·æ–°': 'Refresh',
        'æ¢å¤è®­ç»ƒ': 'Resume training',
        "æ¨ç†": "Inference",
        "æ¨ç†è¯´æ˜": "Inference instructions",
        "### æ¨ç†å‚æ•°è®¾ç½®": "### Inference parameter settings",
        "å˜è°ƒ": "Pitch shift",
        "æ–‡ä»¶åˆ—è¡¨": "File list",
        "é€‰æ‹©è¦å¯¼å‡ºçš„æ¨¡å‹": "Select the model to export",
        "åˆ·æ–°æ¨¡å‹å’ŒéŸ³è‰²": "Refresh model and timbre",
        "å¯¼å‡ºæ¨¡å‹": "Export model",
        "é€‰æ‹©éŸ³è‰²æ–‡ä»¶": "Select timbre file",
        "é€‰æ‹©å¾…è½¬æ¢éŸ³é¢‘": "Select audio to be converted",
        "å¼€å§‹è½¬æ¢": "Start conversion",
        "è¾“å‡ºéŸ³é¢‘": "Output audio",
        "æ‰“å¼€æ–‡ä»¶å¤¹å¤±è´¥ï¼": "Failed to open folder!",
        "å¼€å§‹é¢„å¤„ç†": "Start preprocessing",
        "å¼€å§‹è®­ç»ƒ": "Start training",
        "å¼€å§‹å¯¼å‡ºæ¨¡å‹": "Start exporting model",
        "å¯¼å‡ºæ¨¡å‹æˆåŠŸ": "Model exported successfully",
        "å‡ºç°é”™è¯¯ï¼š": "An error occurred:",
        "ç¼ºå°‘æ¨¡å‹æ–‡ä»¶": "Missing model file",
        'ç¼ºå°‘æ–‡ä»¶': 'Missing file',
        "å·²æ¸…ç†æ®‹ç•™æ–‡ä»¶": "Residual files cleaned up",
        "æ— éœ€æ¸…ç†æ®‹ç•™æ–‡ä»¶": "No need to clean up residual files",
        "å¼€å§‹æ¨ç†": "Start inference",
        '### 2023.7.11|[@OOPPEENN](https://github.com/OOPPEENN)ç¬¬ä¸€æ¬¡ç¼–å†™|[@thestmitsuk](https://github.com/thestmitsuki)äºŒæ¬¡è¡¥å®Œ': '### 2023.7.11|[@OOPPEENN](https://github.com/OOPPEENN)first writing|[@thestmitsuk](https://github.com/thestmitsuki)second completion'
    }
}

class I18nAuto:
    def __init__(self, language=None):
        self.language_list = LANGUAGE_LIST
        self.language_all = LANGUAGE_ALL
        self.language_map = {}
        self.language = language or locale.getdefaultlocale()[0]
        if self.language not in self.language_list:
            self.language = 'zh_CN'
        self.read_language(self.language_all['zh_CN'])
        while self.language_all[self.language]['SUPER'] != 'END':
            self.read_language(self.language_all[self.language])
            self.language = self.language_all[self.language]['SUPER']

    def read_language(self, lang_dict: dict):
        self.language_map.update(lang_dict)

    def __call__(self, key):
        return self.language_map[key]



 

def get_file_options(directory, extension):
    return [file for file in os.listdir(directory) if file.endswith(extension)]


def split_wav(input_file, output_dir, duration=8):
    # æ‰“å¼€WAVæ–‡ä»¶
    with wave.open(input_file, 'rb') as wav_file:
        # è·å–éŸ³é¢‘å‚æ•°
        params = wav_file.getparams()
        num_channels = params.nchannels
        sample_width = params.sampwidth
        frame_rate = params.framerate
        num_frames = params.nframes

        # è®¡ç®—æ¯æ®µéŸ³é¢‘çš„å¸§æ•°
        segment_frames = int(duration * frame_rate)

        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)

        # è¯»å–éŸ³é¢‘æ•°æ®
        frames = wav_file.readframes(num_frames)
        audio_data = np.frombuffer(frames, dtype=np.int16)

        # åˆ‡åˆ†éŸ³é¢‘æ•°æ®
        num_segments = len(audio_data) // segment_frames + int(len(audio_data) % segment_frames > 0)
        for i in range(num_segments):
            segment_start = i * segment_frames
            segment_end = (i + 1) * segment_frames
            segment_data = audio_data[segment_start:segment_end]

            # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å
            basename_path = os.path.basename(input_file).rsplit('.', maxsplit=1)[0]
            segment_filename = basename_path + f"_{i+1}.wav"
            segment_filepath = os.path.join(output_dir, segment_filename)

            # å†™å…¥åˆ‡åˆ†åçš„éŸ³é¢‘æ•°æ®åˆ°è¾“å‡ºæ–‡ä»¶
            with wave.open(segment_filepath, 'wb') as segment_wav:
                segment_wav.setparams(params)
                segment_wav.writeframes(segment_data.tobytes())

    print("éŸ³é¢‘åˆ‡åˆ†å®Œæˆï¼")


def concatenate_wav_files(input_files, output_file):
    merged_audio = None

    for file in input_files:
        audio = AudioSegment.from_wav(file)

        if merged_audio is None:
            merged_audio = audio
        else:
            # å°†éŸ³é¢‘æ–‡ä»¶è¿›è¡Œæ‹¼æ¥
            merged_audio += audio

    # å¯¼å‡ºåˆå¹¶åçš„éŸ³é¢‘æ–‡ä»¶
    merged_audio.export(output_file, format='wav')


# def merge_audio_files(file1, file2, output_file, decibel_reduction=5):
#     audio1 = AudioSegment.from_file(file1)
#     audio2 = AudioSegment.from_file(file2)

#     # è®¡ç®—audio2é™ä½æŒ‡å®šåˆ†è´åçš„æ–°éŸ³é‡
#     new_volume = audio2.dBFS - decibel_reduction
#     audio2 = audio2.apply_gain(new_volume - audio2.dBFS)

#     # å°†ä¸¤ä¸ªéŸ³é¢‘æ–‡ä»¶è¿›è¡Œå åŠ 
#     merged_audio = audio1.overlay(audio2)

#     # å¯¼å‡ºåˆå¹¶åçš„éŸ³é¢‘æ–‡ä»¶
#     merged_audio.export(output_file, format='wav')

from pydub import AudioSegment

def merge_audio_files(start_position_ms, file1, file2, output_file, decibel_reduction):
    
    # ä»æ–‡ä»¶åŠ è½½éŸ³é¢‘
    audio1 = AudioSegment.from_file(file1)
    audio2 = AudioSegment.from_file(file2)

    # è®¡ç®—audio1å¢åŠ æŒ‡å®šåˆ†è´åçš„æ–°éŸ³é‡
    new_volume = audio1.dBFS + decibel_reduction
    audio1 = audio1.apply_gain(new_volume - audio1.dBFS)

    # å°†audio1æ’å…¥åˆ°audio2çš„æŒ‡å®šä½ç½®
    part_before = audio2[:start_position_ms]
    part_after = audio2[start_position_ms + len(audio1):]
    merged_audio = part_before + audio1.overlay(audio2[start_position_ms : start_position_ms + len(audio1)]) + part_after

    # å¯¼å‡ºåˆå¹¶åçš„éŸ³é¢‘æ–‡ä»¶
    merged_audio.export(output_file, format='wav')

# ä½¿ç”¨ä¾‹å­
# merge_audio_files("path_to_file1.wav", "path_to_file2.wav", "output.wav", start_position_ms=5000)



debug = True
local_model_root = 'weights'
# Author_ZH = {"ä¸“ä¸šå¥³æ­Œæ‰‹":"ä¸“ä¸šå¥³æ­Œæ‰‹","yuhui":"RDç‘œæ™–","nifeng":"Paddleå°å€ª", "Jay_Chou": "å‘¨æ°ä¼¦", "ljr": "æ¢é™èŒ¹", "dlj":"é‚“ä¸½å›", "luyao":"Paddleå°é¹¿","yujun":"Paddleå°å†›"}
# Author_EN = {"ä¸“ä¸šå¥³æ­Œæ‰‹":"ä¸“ä¸šå¥³æ­Œæ‰‹","RDç‘œæ™–":"yuhui", "Paddleå°å€ª":"nifeng", "Paddleå°å†›": "yujun", "å‘¨æ°ä¼¦" : "Jay_Chou" ,"æ¢é™èŒ¹": "ljr", "é‚“ä¸½å›":"dlj", "Paddleå°é¹¿":"luyao"}
# Author_Sing = {"ä¸“ä¸šå¥³æ­Œæ‰‹":"å®å¤-æ”¹æ­Œè¯","RDç‘œæ™–":"yuhui", "Paddleå°å€ª":"nifeng", "Paddleå°å†›":"ç¿»å”±-ç™½æœˆå…‰ä¸æœ±ç ‚ç—£", "Paddleå°é¹¿":"ç¿»å”±å‘¨æ°ä¼¦-å‘å¦‚é›ª", "å‘¨æ°ä¼¦" : "ç¿»å”±å¥³ç”Ÿç‰ˆ-ç²‰è‰²æµ·æ´‹" ,"æ¢é™èŒ¹": "ç¿»å”±å¼ éŸ¶æ¶µ-äº²çˆ±çš„é‚£ä¸æ˜¯çˆ±æƒ…", "é‚“ä¸½å›":"ç¿»å”±æ—¥è¯­ç‰ˆ-æˆ‘åªåœ¨ä¹ä½ "}
    # "ğŸ”¥æ˜Ÿè¾‰å¥³éŸ³-å¥³æ­Œæ‰‹ğŸ‘©â€ğŸ¤": 0,
    # "ğŸ”¥æ‘‡æ»šå…ˆé”‹-ç”·æ­Œæ‰‹ğŸ‘¨â€ğŸ¤": -10,
    # 'ğŸ”¥æµè¡ŒéŸ³ç‹-ç”·æ­Œæ‰‹ğŸ‘¨â€ğŸ¤': -2, 
    # "ğŸ”¥æ¸©æŸ”æƒ…æ­Œ-å¥³æ­Œæ‰‹ğŸ‘©â€ğŸ¤":  0,
    # "ğŸ”¥ç»å…¸å¤©ç±-å¥³æ­Œæ‰‹ğŸ‘©â€ğŸ¤": -3,
Author_ZH = {"ğŸ”¥æ˜Ÿè¾‰å¥³éŸ³-å¥³æ­Œæ‰‹ğŸ‘©â€ğŸ¤":"ğŸ”¥æ˜Ÿè¾‰å¥³éŸ³-å¥³æ­Œæ‰‹ğŸ‘©â€ğŸ¤","yuhui":"ğŸ”¥æ‘‡æ»šå…ˆé”‹-ç”·æ­Œæ‰‹ğŸ‘¨â€ğŸ¤",'zh':"ğŸ”¥é­…å£°å°‘å¹´-ç”·æ­Œæ‰‹ğŸ‘¨â€ğŸ¤", "ljr": "ğŸ”¥æ¸©æŸ”æƒ…æ­Œ-å¥³æ­Œæ‰‹ğŸ‘©â€ğŸ¤", "luyao":"ğŸ”¥å®‡å®™å°‘å¥³-å¥³æ­Œæ‰‹ğŸ‘©â€ğŸ¤", "mgr":"ğŸ”¥é“¶å¹•éŸ³é­‚-ç”·æ­Œæ‰‹ğŸ‘¨â€ğŸ¤"}
Author_EN = {"ğŸ”¥æ˜Ÿè¾‰å¥³éŸ³-å¥³æ­Œæ‰‹ğŸ‘©â€ğŸ¤":"ğŸ”¥æ˜Ÿè¾‰å¥³éŸ³-å¥³æ­Œæ‰‹ğŸ‘©â€ğŸ¤","ğŸ”¥æ‘‡æ»šå…ˆé”‹-ç”·æ­Œæ‰‹ğŸ‘¨â€ğŸ¤":"yuhui", "ğŸ”¥é­…å£°å°‘å¹´-ç”·æ­Œæ‰‹ğŸ‘¨â€ğŸ¤":"zh", "ğŸ”¥æ¸©æŸ”æƒ…æ­Œ-å¥³æ­Œæ‰‹ğŸ‘©â€ğŸ¤": "ljr", "ğŸ”¥å®‡å®™å°‘å¥³-å¥³æ­Œæ‰‹ğŸ‘©â€ğŸ¤":"luyao", "ğŸ”¥é“¶å¹•éŸ³é­‚-ç”·æ­Œæ‰‹ğŸ‘¨â€ğŸ¤": "mgr"}
Author_Sing = {"ğŸ”¥æ˜Ÿè¾‰å¥³éŸ³-å¥³æ­Œæ‰‹ğŸ‘©â€ğŸ¤":"æ˜Ÿè¾‰å¥³éŸ³","ğŸ”¥æ‘‡æ»šå…ˆé”‹-ç”·æ­Œæ‰‹ğŸ‘¨â€ğŸ¤":"æ‘‡æ»šå…ˆé”‹","ğŸ”¥é­…å£°å°‘å¹´-ç”·æ­Œæ‰‹ğŸ‘¨â€ğŸ¤":"é­…å£°å°‘å¹´", "ğŸ”¥æ¸©æŸ”æƒ…æ­Œ-å¥³æ­Œæ‰‹ğŸ‘©â€ğŸ¤": "æ¸©æŸ”æƒ…æ­Œ", "ğŸ”¥å®‡å®™å°‘å¥³-å¥³æ­Œæ‰‹ğŸ‘©â€ğŸ¤":"å®‡å®™å°‘å¥³", "ğŸ”¥é“¶å¹•éŸ³é­‚-ç”·æ­Œæ‰‹ğŸ‘¨â€ğŸ¤":"é“¶å¹•éŸ³é­‚"}

output_format = "wav"
# vc_transform = 0
cluster_ratio = 0.3
slice_db = -40
noise_scale = 0.4
pad_seconds = 0.5
cl_num = 0
lg_num = 0
lgr_num = 0.75
f0_predictor = "pm"
enhancer_adaptive_key = 0
cr_threshold = 0.05
k_step = 100
use_spk_mix = False
second_encoding = False
loudness_envelope_adjustment = 0

cuda = {}

spks = list([_name for _name in Author_ZH.values()])

ckpt_list = []
create_list = ["æ¨¡æ¿ä½œæ›²", "è‡ªåŠ¨ä½œæ›²"]
songs_list = list([_name for _name in Songs_CN_dict.keys()])
style_list = SongsType.keys()
model = None
SINGERS = list([_name for _name in Singer_F_dict.keys()])

i18n = I18nAuto()


if torch.cuda.is_available():
    for i in range(torch.cuda.device_count()):
        device_name = torch.cuda.get_device_properties(i).name
        cuda[f"CUDA:{i} {device_name}"] = f"cuda:{i}"
        

def modelAnalysis(device, sid, msg, choice_ckpt):
    global model, spks, Author_ZH, Author_EN

    extra_author = glob.glob("assets/weights/*.pth")
    for author in extra_author:
        filename = os.path.basename(author) 
        name, _ = os.path.splitext(filename)
        if name not in Author_ZH.keys():
            Author_ZH.update({name:name})
            Author_EN.update({name:name})
            Author_Sing.update({name:""})

    device = cuda[device] if "CUDA" in device else device

    device=device if device != "Auto" else None

    if device is None:
        dev = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    else:
        dev = torch.device(device)

    print(device)
    if sid != "ğŸ”¥æ˜Ÿè¾‰å¥³éŸ³-å¥³æ­Œæ‰‹ğŸ‘©â€ğŸ¤":
        vc.get_vc(choice_ckpt,0.33,0.33)

    model_path = os.path.join(local_model_root, Author_EN[sid], "logs", choice_ckpt)
    
    device_name = torch.cuda.get_device_properties(dev).name if "cuda" in str(dev) else str(dev)
    _name = "weights/"
    msg = f"æˆåŠŸåŠ è½½æ¨¡å‹åˆ°è®¾å¤‡{device_name}ä¸Š\n"
    msg += f"æ¨¡å‹{model_path.split(_name)[1]}åŠ è½½æˆåŠŸ\n"
    msg += "å½“å‰æ¨¡å‹çš„å¯ç”¨éŸ³è‰²ï¼š\n"
    for i in SINGERS:
        msg += i + " "

    model = model_path

    return sid, msg



def vc_batch_fn(sid, input_audio, auto_f0, vc_transform, choice_ckpt):

    global model
        
    print(i18n('å¼€å§‹æ¨ç†'))
    print(f"Start processing: {input_audio}")
    # import pdb
    # pdb.set_trace()
    index_file = glob.glob(f"logs/{Author_EN[sid]}/added*.index")[0]
    spk_item=0
    input_audio0=input_audio
    vc_transform0=vc_transform
    f0_file=None
    f0method0="rmvpe"
    file_index1=index_file
    file_index2=index_file
    index_rate1=0.75
    filter_radius0=3
    resample_sr0=0
    rms_mix_rate0=0.25
    protect0=0.33

    vc_output1, vc_output2 = vc.vc_single(spk_item,input_audio0, vc_transform0, f0_file, f0method0, file_index1, file_index2,index_rate1, filter_radius0,resample_sr0, rms_mix_rate0, protect0) 
    
    print(i18n("æ¨ç†æˆåŠŸ"))
    return "éŸ³ä¹åˆæˆæˆåŠŸå•¦ï¼Œå¿«æ¥å¬å¬å§!", vc_output2

def refresh_options(sid, vc_transform, exp_sex):
    # import pdb
    # pdb.set_trace()
    global ckpt_list, Author_Sing, spks, Author_ZH

    if Author_Sing[sid]:
        audio_wav_file = Author_Sing[sid] + '.wav'
    else:
        audio_wav_file = None

    if sid not in Singer_F_dict.keys():
        if exp_sex=="ç”·å£°":
            vc_transform = -10
        else:
            vc_transform = 0
    else:
        vc_transform = Singer_F_dict[sid]
        
    if sid == "ğŸ”¥æ˜Ÿè¾‰å¥³éŸ³-å¥³æ­Œæ‰‹ğŸ‘©â€ğŸ¤":
        return gr.Dropdown.update(choices=spks,value=sid), gr.Dropdown.update(choices=[], value="é»˜è®¤"), gr.Audio.update(label=Author_Sing[sid], value=audio_wav_file, interactive=False), vc_transform, ""
    
    ckpt_list = [file for file in get_file_options(os.path.join(now_dir, "assets/weights"), f"{Author_EN[sid]}.pth")]
    print("ckpt_list: ",ckpt_list, sid, f"{ Author_EN[sid]}.pth")
    spks = list([_name for _name in Author_Sing.keys()])
    
    return gr.Dropdown(label="éŸ³è‰²ï¼ˆæ­Œæ‰‹ï¼‰", choices=spks,value=str(sid)), gr.Dropdown.update(choices=ckpt_list,value=ckpt_list[0]), gr.Audio.update(label=Author_Sing[sid], value=audio_wav_file, interactive=False), vc_transform, ""

sr_dict = {
    "32k": 32000,
    "40k": 40000,
    "48k": 48000,
}


def click_train(
    exp_dir1,
    sr2,
    if_f0_3,
    spk_id5,
    save_epoch10,
    total_epoch11,
    batch_size12,
    if_save_latest13,
    pretrained_G14,
    pretrained_D15,
    gpus16,
    if_cache_gpu17,
    if_save_every_weights18,
    version19,
):
    # ç”Ÿæˆfilelist
    exp_dir = "%s/logs/%s" % (now_dir, exp_dir1)
    os.makedirs(exp_dir, exist_ok=True)
    gt_wavs_dir = "%s/0_gt_wavs" % (exp_dir)
    feature_dir = (
        "%s/3_feature256" % (exp_dir)
        if version19 == "v1"
        else "%s/3_feature768" % (exp_dir)
    )
    if if_f0_3:
        f0_dir = "%s/2a_f0" % (exp_dir)
        f0nsf_dir = "%s/2b-f0nsf" % (exp_dir)
        names = (
            set([name.split(".")[0] for name in os.listdir(gt_wavs_dir)])
            & set([name.split(".")[0] for name in os.listdir(feature_dir)])
            & set([name.split(".")[0] for name in os.listdir(f0_dir)])
            & set([name.split(".")[0] for name in os.listdir(f0nsf_dir)])
        )
    else:
        names = set([name.split(".")[0] for name in os.listdir(gt_wavs_dir)]) & set(
            [name.split(".")[0] for name in os.listdir(feature_dir)]
        )
    opt = []
    for name in names:
        if if_f0_3:
            opt.append(
                "%s/%s.wav|%s/%s.npy|%s/%s.wav.npy|%s/%s.wav.npy|%s"
                % (
                    gt_wavs_dir.replace("\\", "\\\\"),
                    name,
                    feature_dir.replace("\\", "\\\\"),
                    name,
                    f0_dir.replace("\\", "\\\\"),
                    name,
                    f0nsf_dir.replace("\\", "\\\\"),
                    name,
                    spk_id5,
                )
            )
        else:
            opt.append(
                "%s/%s.wav|%s/%s.npy|%s"
                % (
                    gt_wavs_dir.replace("\\", "\\\\"),
                    name,
                    feature_dir.replace("\\", "\\\\"),
                    name,
                    spk_id5,
                )
            )
    fea_dim = 256 if version19 == "v1" else 768
    if if_f0_3:
        for _ in range(2):
            opt.append(
                "%s/logs/mute/0_gt_wavs/mute%s.wav|%s/logs/mute/3_feature%s/mute.npy|%s/logs/mute/2a_f0/mute.wav.npy|%s/logs/mute/2b-f0nsf/mute.wav.npy|%s"
                % (now_dir, sr2, now_dir, fea_dim, now_dir, now_dir, spk_id5)
            )
    else:
        for _ in range(2):
            opt.append(
                "%s/logs/mute/0_gt_wavs/mute%s.wav|%s/logs/mute/3_feature%s/mute.npy|%s"
                % (now_dir, sr2, now_dir, fea_dim, spk_id5)
            )
    shuffle(opt)
    with open("%s/filelist.txt" % exp_dir, "w") as f:
        f.write("\n".join(opt))
    logger.debug("Write filelist done")
    # ç”Ÿæˆconfig#æ— éœ€ç”Ÿæˆconfig
    # cmd = python_cmd + " train_nsf_sim_cache_sid_load_pretrain.py -e mi-test -sr 40k -f0 1 -bs 4 -g 0 -te 10 -se 5 -pg pretrained/f0G40k.pth -pd pretrained/f0D40k.pth -l 1 -c 0"
    logger.info("Use gpus: %s", str(gpus16))
    if pretrained_G14 == "":
        logger.info("No pretrained Generator")
    if pretrained_D15 == "":
        logger.info("No pretrained Discriminator")
    if version19 == "v1" or sr2 == "40k":
        config_path = "v1/%s.json" % sr2
    else:
        config_path = "v2/%s.json" % sr2
    config_save_path = os.path.join(exp_dir, "config.json")
    if not pathlib.Path(config_save_path).exists():
        with open(config_save_path, "w", encoding="utf-8") as f:
            json.dump(
                config.json_config[config_path],
                f,
                ensure_ascii=False,
                indent=4,
                sort_keys=True,
            )
            f.write("\n")
    if gpus16:
        cmd = (
            '"%s" infer/modules/train/train.py -e "%s" -sr %s -f0 %s -bs %s -g %s -te %s -se %s %s %s -l %s -c %s -sw %s -v %s'
            % (
                config.python_cmd,
                exp_dir1,
                sr2,
                1 if if_f0_3 else 0,
                batch_size12,
                gpus16,
                total_epoch11,
                save_epoch10,
                "-pg %s" % pretrained_G14 if pretrained_G14 != "" else "",
                "-pd %s" % pretrained_D15 if pretrained_D15 != "" else "",
                1 if if_save_latest13 == i18n("æ˜¯") else 0,
                1 if if_cache_gpu17 == i18n("æ˜¯") else 0,
                1 if if_save_every_weights18 == i18n("æ˜¯") else 0,
                version19,
            )
        )
    else:
        cmd = (
            '"%s" infer/modules/train/train.py -e "%s" -sr %s -f0 %s -bs %s -te %s -se %s %s %s -l %s -c %s -sw %s -v %s'
            % (
                config.python_cmd,
                exp_dir1,
                sr2,
                1 if if_f0_3 else 0,
                batch_size12,
                total_epoch11,
                save_epoch10,
                "-pg %s" % pretrained_G14 if pretrained_G14 != "" else "",
                "-pd %s" % pretrained_D15 if pretrained_D15 != "" else "",
                1 if if_save_latest13 == i18n("æ˜¯") else 0,
                1 if if_cache_gpu17 == i18n("æ˜¯") else 0,
                1 if if_save_every_weights18 == i18n("æ˜¯") else 0,
                version19,
            )
        )
    # logger.info(cmd)
    p = Popen(cmd, shell=True, cwd=now_dir)
    p.wait()
    return "è®­ç»ƒç»“æŸ, æ‚¨å¯æŸ¥çœ‹æ§åˆ¶å°è®­ç»ƒæ—¥å¿—æˆ–å®éªŒæ–‡ä»¶å¤¹ä¸‹çš„train.log"


# but4.click(train_index, [exp_dir1], info3)
def train_index(exp_dir1, version19):
    # exp_dir = "%s/logs/%s" % (now_dir, exp_dir1)
    exp_dir = "logs/%s" % (exp_dir1)
    os.makedirs(exp_dir, exist_ok=True)
    feature_dir = (
        "%s/3_feature256" % (exp_dir)
        if version19 == "v1"
        else "%s/3_feature768" % (exp_dir)
    )
    if not os.path.exists(feature_dir):
        return "è¯·å…ˆè¿›è¡Œç‰¹å¾æå–!"
    listdir_res = list(os.listdir(feature_dir))
    if len(listdir_res) == 0:
        return "è¯·å…ˆè¿›è¡Œç‰¹å¾æå–ï¼"
    infos = []
    npys = []
    for name in sorted(listdir_res):
        phone = np.load("%s/%s" % (feature_dir, name))
        npys.append(phone)
    big_npy = np.concatenate(npys, 0)
    big_npy_idx = np.arange(big_npy.shape[0])
    np.random.shuffle(big_npy_idx)
    big_npy = big_npy[big_npy_idx]
    if big_npy.shape[0] > 2e5:
        infos.append("Trying doing kmeans %s shape to 10k centers." % big_npy.shape[0])
        yield "\n".join(infos)
        try:
            big_npy = (
                MiniBatchKMeans(
                    n_clusters=10000,
                    verbose=True,
                    batch_size=256 * config.n_cpu,
                    compute_labels=False,
                    init="random",
                )
                .fit(big_npy)
                .cluster_centers_
            )
        except:
            info = traceback.format_exc()
            # logger.info(info)
            infos.append(info)
            yield "\n".join(infos)

    np.save("%s/total_fea.npy" % exp_dir, big_npy)
    n_ivf = min(int(16 * np.sqrt(big_npy.shape[0])), big_npy.shape[0] // 39)
    infos.append("%s,%s" % (big_npy.shape, n_ivf))
    yield "\n".join(infos)
    index = faiss.index_factory(256 if version19 == "v1" else 768, "IVF%s,Flat" % n_ivf)
    # index = faiss.index_factory(256if version19=="v1"else 768, "IVF%s,PQ128x4fs,RFlat"%n_ivf)
    infos.append("training")
    yield "\n".join(infos)
    index_ivf = faiss.extract_index_ivf(index)  #
    index_ivf.nprobe = 1
    index.train(big_npy)
    faiss.write_index(
        index,
        "%s/trained_IVF%s_Flat_nprobe_%s_%s_%s.index"
        % (exp_dir, n_ivf, index_ivf.nprobe, exp_dir1, version19),
    )

    infos.append("adding")
    yield "\n".join(infos)
    batch_size_add = 8192
    for i in range(0, big_npy.shape[0], batch_size_add):
        index.add(big_npy[i : i + batch_size_add])
    faiss.write_index(
        index,
        "%s/added_IVF%s_Flat_nprobe_%s_%s_%s.index"
        % (exp_dir, n_ivf, index_ivf.nprobe, exp_dir1, version19),
    )
    infos.append(
        "æˆåŠŸæ„å»ºç´¢å¼•ï¼Œadded_IVF%s_Flat_nprobe_%s_%s_%s.index"
        % (n_ivf, index_ivf.nprobe, exp_dir1, version19)
    )
    # faiss.write_index(index, '%s/added_IVF%s_Flat_FastScan_%s.index'%(exp_dir,n_ivf,version19))
    # infos.append("æˆåŠŸæ„å»ºç´¢å¼•ï¼Œadded_IVF%s_Flat_FastScan_%s.index"%(n_ivf,version19))
    yield "\n".join(infos)


# but5.click(train1key, [exp_dir1, sr2, if_f0_3, trainset_dir4, spk_id5, gpus6, np7, f0method8, save_epoch10, total_epoch11, batch_size12, if_save_latest13, pretrained_G14, pretrained_D15, gpus16, if_cache_gpu17], info3)
def train1key( 
    sid,
    exp_sex,
    exp_dir1,
    sr2,
    if_f0_3,
    record_audio_prompt,
    trainset_dir4,
    spk_id5,
    np7,
    f0method8,
    save_epoch10,
    total_epoch11,
    batch_size12,
    if_save_latest13,
    pretrained_G14,
    pretrained_D15,
    gpus16,
    if_cache_gpu17,
    if_save_every_weights18,
    version19,
    gpus_rmvpe,
):

    infos = []

    def get_info_str(strr):
        infos.append(strr)
        return "\n".join(infos)


    global Author_ZH, Author_EN, Author_Sing
    os.system(f"cp -r assets/weights/yuhui.pth {exp_dir1}.pth")
    os.system(f"cp -r logs/yuhui logs/{exp_dir1}")    
    yield get_info_str("å¿«å»ç‚¹å‡»åœ¨çº¿ä½“éªŒè¯•è¯•ä½ çš„å£°éŸ³å§ï¼"), exp_dir1



#     if not exp_dir1:
#         yield get_info_str("è¯·ç»™å£°éŸ³æ¨¡å‹å–ä¸ªåå­—å§ï½"), sid
#         return 
#     if not exp_sex:
#         yield get_info_str("è¯·é€‰æ‹©ç”·å£°orå¥³å£°ï½"), sid
#         return

#     # step1:å¤„ç†æ•°æ®
#     yield get_info_str(i18n("step1:æ­£åœ¨å¤„ç†æ•°æ®")), exp_dir1
#     if record_audio_prompt:
#         trainset_dir4 = [record_audio_prompt]
#     [get_info_str(_) for _ in preprocess_dataset(trainset_dir4, exp_dir1, sr2, np7)]

#     # step2a:æå–éŸ³é«˜
#     yield get_info_str(i18n("step2:æ­£åœ¨æå–éŸ³é«˜&æ­£åœ¨æå–ç‰¹å¾")), exp_dir1
#     [
#         get_info_str(_)
#         for _ in extract_f0_feature(
#             gpus16, np7, f0method8, if_f0_3, exp_dir1, version19, gpus_rmvpe
#         )
#     ]

#     # step3a:è®­ç»ƒæ¨¡å‹
#     yield get_info_str(i18n("step3a:æ­£åœ¨è®­ç»ƒæ¨¡å‹")), exp_dir1


#     future = training_threadpool.submit(click_train(
#         exp_dir1,
#         sr2,
#         if_f0_3,
#         spk_id5,
#         save_epoch10,
#         total_epoch11,
#         batch_size12,
#         if_save_latest13,
#         pretrained_G14,
#         pretrained_D15,
#         gpus16,
#         if_cache_gpu17,
#         if_save_every_weights18,
#         version19,
#     ) )

#     start_time = time.time()

#     while not future.done():
#         is_processing = future.running()
#         if  is_processing:
#             passed_time = int(time.time() - start_time)
#             # yield get_info_str("è®­ç»ƒä¸­, é¢„è®¡éœ€è¦180ç§’, è¯·è€å¿ƒç­‰å¾…, å½“å‰å·²ç­‰å¾…{}ç§’...".format(passed_time)), exp_dir1
#         time.sleep(1)

#     # step3b:è®­ç»ƒç´¢å¼•
#     [get_info_str(_) for _ in train_index(exp_dir1, version19)]
#     yield get_info_str(i18n("è®­ç»ƒç»“æŸ, æ‚¨å¯æŸ¥çœ‹æ§åˆ¶å°è®­ç»ƒæ—¥å¿—æˆ–å®éªŒæ–‡ä»¶å¤¹ä¸‹çš„train.log")), exp_dir1

#     os.system("mv logs/{}/add* ../".format(exp_dir1))
#     os.system("rm -rf logs/{}/* ".format(exp_dir1))
    # os.system("mv ../add* logs/{}/".format(exp_dir1))
    # os.system(f"ls logs/{exp_dir1}")
    

#     _Author_ZH = {exp_dir1 : exp_dir1}
#     _Author_EN = {exp_dir1 : exp_dir1}
#     _Author_Sing = {exp_dir1 : ""}

#     _Author_ZH.update(Author_ZH)
#     Author_ZH = _Author_ZH
#     _Author_EN.update(Author_EN)
#     Author_EN = _Author_EN
#     _Author_Sing.update(Author_Sing)
#     Author_Sing = _Author_Sing
#     print(Author_ZH, Author_EN, Author_Sing)
    

#     yield get_info_str("å¿«å»ç‚¹å‡»åœ¨çº¿ä½“éªŒè¯•è¯•ä½ çš„å£°éŸ³å§ï¼"), exp_dir1


#                    ckpt_path2.change(change_info_,[ckpt_path2],[sr__,if_f0__])
def change_info_(ckpt_path):
    if not os.path.exists(ckpt_path.replace(os.path.basename(ckpt_path), "train.log")):
        return {"__type__": "update"}, {"__type__": "update"}, {"__type__": "update"}
    try:
        with open(
            ckpt_path.replace(os.path.basename(ckpt_path), "train.log"), "r"
        ) as f:
            info = eval(f.read().strip("\n").split("\n")[0].split("\t")[-1])
            sr, f0 = info["sample_rate"], info["if_f0"]
            version = "v2" if ("version" in info and info["version"] == "v2") else "v1"
            return sr, str(f0), version
    except:
        traceback.print_exc()
        return {"__type__": "update"}, {"__type__": "update"}, {"__type__": "update"}


F0GPUVisible = config.dml == False


def if_done(done, p):
    while 1:
        if p.poll() is None:
            sleep(0.5)
        else:
            break
    done[0] = True

def if_done_multi(done, ps):
    while 1:
        # poll==Noneä»£è¡¨è¿›ç¨‹æœªç»“æŸ
        # åªè¦æœ‰ä¸€ä¸ªè¿›ç¨‹æœªç»“æŸéƒ½ä¸åœ
        flag = 1
        for p in ps:
            if p.poll() is None:
                flag = 0
                sleep(0.5)
                break
        if flag == 1:
            break
    done[0] = True


def preprocess_dataset(trainset_dir, exp_dir, sr, n_p):
    # import pdb
    # pdb.set_trace()
    if exp_dir:
        os.system("rm -rf %s/datasets/%s" % (now_dir, exp_dir))
        os.system("rm -rf %s/logs/%s" % (now_dir, exp_dir))
    os.makedirs("%s/datasets/%s" % (now_dir, exp_dir), exist_ok=True)

    paths = trainset_dir
    if not isinstance(trainset_dir[0], str):
        paths = [path.name for path in paths]
    cnt = 0
    for path in paths:
        shutil.move(path, "%s/datasets/%s" % (now_dir, exp_dir) )

    trainset_dir = "%s/datasets/%s" % (now_dir, exp_dir)

    sr = sr_dict[sr]
    os.makedirs("%s/logs/%s" % (now_dir, exp_dir), exist_ok=True)

    f = open("%s/logs/%s/preprocess.log" % (now_dir, exp_dir), "w")
    f.close()
    per = 3.0 if config.is_half else 3.7
    cmd = '"%s" infer/modules/train/preprocess.py "%s" %s %s "%s/logs/%s" %s %.1f' % (
        config.python_cmd,
        trainset_dir,
        sr,
        n_p,
        now_dir,
        exp_dir,
        config.noparallel,
        per,
    )
    # logger.info(cmd)
    # , stdin=PIPE, stdout=PIPE,stderr=PIPE,cwd=now_dir
    p = Popen(cmd, shell=True)
    # ç…ç¬”gr, popen readéƒ½éå¾—å…¨è·‘å®Œäº†å†ä¸€æ¬¡æ€§è¯»å–, ä¸ç”¨grå°±æ­£å¸¸è¯»ä¸€å¥è¾“å‡ºä¸€å¥;åªèƒ½é¢å¤–å¼„å‡ºä¸€ä¸ªæ–‡æœ¬æµå®šæ—¶è¯»
    done = [False]
    threading.Thread(
        target=if_done,
        args=(
            done,
            p,
        ),
    ).start()
    while 1:
        with open("%s/logs/%s/preprocess.log" % (now_dir, exp_dir), "r") as f:
            yield (f.read())
        sleep(1)
        if done[0]:
            break
    with open("%s/logs/%s/preprocess.log" % (now_dir, exp_dir), "r") as f:
        log = f.read()
    # logger.info(log)
    yield log


def get_pretrained_models(path_str, f0_str, sr2):
    if_pretrained_generator_exist = os.access(
        "assets/pretrained%s/%sG%s.pth" % (path_str, f0_str, sr2), os.F_OK
    )
    if_pretrained_discriminator_exist = os.access(
        "assets/pretrained%s/%sD%s.pth" % (path_str, f0_str, sr2), os.F_OK
    )
    if not if_pretrained_generator_exist:
        logger.warning(
            "assets/pretrained%s/%sG%s.pth not exist, will not use pretrained model",
            path_str,
            f0_str,
            sr2,
        )
    if not if_pretrained_discriminator_exist:
        logger.warning(
            "assets/pretrained%s/%sD%s.pth not exist, will not use pretrained model",
            path_str,
            f0_str,
            sr2,
        )
    return (
        "assets/pretrained%s/%sG%s.pth" % (path_str, f0_str, sr2)
        if if_pretrained_generator_exist
        else "",
        "assets/pretrained%s/%sD%s.pth" % (path_str, f0_str, sr2)
        if if_pretrained_discriminator_exist
        else "",
    )

def change_f0_method(f0method8):
    # if f0method8 == "rmvpe_gpu":
    #     visible = F0GPUVisible
    # else:
    visible = False
    return {"visible": visible, "__type__": "update"}

def change_sr2(sr2, if_f0_3, version19):
    path_str = "" if version19 == "v1" else "_v2"
    f0_str = "f0" if if_f0_3 else ""
    return get_pretrained_models(path_str, f0_str, sr2)

def change_version19(sr2, if_f0_3, version19):
    path_str = "" if version19 == "v1" else "_v2"
    if sr2 == "32k" and version19 == "v1":
        sr2 = "40k"
    to_return_sr2 = (
        {"choices": ["40k", "48k"], "__type__": "update", "value": sr2}
        if version19 == "v1"
        else {"choices": ["40k", "48k", "32k"], "__type__": "update", "value": sr2}
    )
    f0_str = "f0" if if_f0_3 else ""
    return (
        *get_pretrained_models(path_str, f0_str, sr2),
        to_return_sr2,
    )


def change_f0(if_f0_3, sr2, version19):  # f0method8,pretrained_G14,pretrained_D15
    path_str = "" if version19 == "v1" else "_v2"
    return (
        {"visible": if_f0_3, "__type__": "update"},
        {"visible": if_f0_3, "__type__": "update"},
        *get_pretrained_models(path_str, "f0" if if_f0_3 == True else "", sr2),
    )



def extract_f0_feature(gpus, n_p, f0method, if_f0, exp_dir, version19, gpus_rmvpe):
    gpus = gpus.split("-")
    os.makedirs("%s/logs/%s" % (now_dir, exp_dir), exist_ok=True)
    f = open("%s/logs/%s/extract_f0_feature.log" % (now_dir, exp_dir), "w")
    f.close()
    if if_f0:
        if f0method != "rmvpe_gpu":
            cmd = (
                '"%s" infer/modules/train/extract/extract_f0_print.py "%s/logs/%s" %s %s'
                % (
                    config.python_cmd,
                    now_dir,
                    exp_dir,
                    n_p,
                    f0method,
                )
            )
            # logger.info(cmd)
            p = Popen(
                cmd, shell=True, cwd=now_dir
            )  # , stdin=PIPE, stdout=PIPE,stderr=PIPE
            # ç…ç¬”gr, popen readéƒ½éå¾—å…¨è·‘å®Œäº†å†ä¸€æ¬¡æ€§è¯»å–, ä¸ç”¨grå°±æ­£å¸¸è¯»ä¸€å¥è¾“å‡ºä¸€å¥;åªèƒ½é¢å¤–å¼„å‡ºä¸€ä¸ªæ–‡æœ¬æµå®šæ—¶è¯»
            done = [False]
            threading.Thread(
                target=if_done,
                args=(
                    done,
                    p,
                ),
            ).start()
        else:
            if gpus_rmvpe != "-":
                gpus_rmvpe = gpus_rmvpe.split("-")
                leng = len(gpus_rmvpe)
                ps = []
                for idx, n_g in enumerate(gpus_rmvpe):
                    cmd = (
                        '"%s" infer/modules/train/extract/extract_f0_rmvpe.py %s %s %s "%s/logs/%s" %s '
                        % (
                            config.python_cmd,
                            leng,
                            idx,
                            n_g,
                            now_dir,
                            exp_dir,
                            config.is_half,
                        )
                    )
                    # logger.info(cmd)
                    p = Popen(
                        cmd, shell=True, cwd=now_dir
                    )  # , shell=True, stdin=PIPE, stdout=PIPE, stderr=PIPE, cwd=now_dir
                    ps.append(p)
                # ç…ç¬”gr, popen readéƒ½éå¾—å…¨è·‘å®Œäº†å†ä¸€æ¬¡æ€§è¯»å–, ä¸ç”¨grå°±æ­£å¸¸è¯»ä¸€å¥è¾“å‡ºä¸€å¥;åªèƒ½é¢å¤–å¼„å‡ºä¸€ä¸ªæ–‡æœ¬æµå®šæ—¶è¯»
                done = [False]
                threading.Thread(
                    target=if_done_multi,  #
                    args=(
                        done,
                        ps,
                    ),
                ).start()
            else:
                cmd = (
                    config.python_cmd
                    + ' infer/modules/train/extract/extract_f0_rmvpe_dml.py "%s/logs/%s" '
                    % (
                        now_dir,
                        exp_dir,
                    )
                )
                # logger.info(cmd)
                p = Popen(
                    cmd, shell=True, cwd=now_dir
                )  # , shell=True, stdin=PIPE, stdout=PIPE, stderr=PIPE, cwd=now_dir
                p.wait()
                done = [True]
        while 1:
            with open(
                "%s/logs/%s/extract_f0_feature.log" % (now_dir, exp_dir), "r"
            ) as f:
                yield (f.read())
            sleep(1)
            if done[0]:
                break
        with open("%s/logs/%s/extract_f0_feature.log" % (now_dir, exp_dir), "r") as f:
            log = f.read()
        # logger.info(log)
        yield log
    # å¯¹ä¸åŒpartåˆ†åˆ«å¼€å¤šè¿›ç¨‹
    """
    n_part=int(sys.argv[1])
    i_part=int(sys.argv[2])
    i_gpu=sys.argv[3]
    exp_dir=sys.argv[4]
    os.environ["CUDA_VISIBLE_DEVICES"]=str(i_gpu)
    """
    leng = len(gpus)
    ps = []
    for idx, n_g in enumerate(gpus):
        cmd = (
            '"%s" infer/modules/train/extract_feature_print.py %s %s %s %s "%s/logs/%s" %s'
            % (
                config.python_cmd,
                config.device,
                leng,
                idx,
                n_g,
                now_dir,
                exp_dir,
                version19,
            )
        )
        # logger.info(cmd)
        p = Popen(
            cmd, shell=True, cwd=now_dir
        )  # , shell=True, stdin=PIPE, stdout=PIPE, stderr=PIPE, cwd=now_dir
        ps.append(p)
    # ç…ç¬”gr, popen readéƒ½éå¾—å…¨è·‘å®Œäº†å†ä¸€æ¬¡æ€§è¯»å–, ä¸ç”¨grå°±æ­£å¸¸è¯»ä¸€å¥è¾“å‡ºä¸€å¥;åªèƒ½é¢å¤–å¼„å‡ºä¸€ä¸ªæ–‡æœ¬æµå®šæ—¶è¯»
    done = [False]
    threading.Thread(
        target=if_done_multi,
        args=(
            done,
            ps,
        ),
    ).start()
    while 1:
        with open("%s/logs/%s/extract_f0_feature.log" % (now_dir, exp_dir), "r") as f:
            yield (f.read())
        sleep(1)
        if done[0]:
            break
    with open("%s/logs/%s/extract_f0_feature.log" % (now_dir, exp_dir), "r") as f:
        log = f.read()
    # logger.info(log)
    yield log

def cpop_pinyin2ph_func():
    # In the README file of opencpop dataset, they defined a "pinyin to phoneme mapping table"
    pinyin2phs = {'AP': 'AP', 'SP': 'SP'}
    with open('cpop_pinyin2ph.txt') as rf:
        for line in rf.readlines():
            elements = [x.strip() for x in line.split('|') if x.strip() != '']
            pinyin2phs[elements[0]] = elements[1]
    return pinyin2phs

pinyin2phs = cpop_pinyin2ph_func()

def convert_note_midi_dur(text, old_note, old_midi_dur):
    pinyins = lazy_pinyin(text, strict=False)
    ph_per_word_lst = [pinyin2phs[pinyin.strip()]
                        for pinyin in pinyins if pinyin.strip() in pinyin2phs]

    # Note
    note_per_word_lst = [x.strip()
                            for x in old_note.split('|') if x.strip() != '']
    mididur_per_word_lst = [
        x.strip() for x in old_midi_dur.split('|') if x.strip() != '']

    note_lst = []
    ph_lst = []
    midi_dur_lst = []
    is_slur = []
    for idx, ph_per_word in enumerate(ph_per_word_lst):
        # for phs in one word:
        # single ph like ['ai']  or multiple phs like ['n', 'i']
        ph_in_this_word = ph_per_word.split()

        # for notes in one word:
        # single note like ['D4'] or multiple notes like ['D4', 'E4'] which means a 'slur' here.
        note_in_this_word = note_per_word_lst[idx].split()
        midi_dur_in_this_word = mididur_per_word_lst[idx].split()
        # process for the model input
        # Step 1.
        #  Deal with note of 'not slur' case or the first note of 'slur' case
        #  j        ie
        #  F#4/Gb4  F#4/Gb4
        #  0        0
        # if ph_in_this_word[0] == "SP":
        #     print(midi_dur_in_this_word[0])
        
        for ph in ph_in_this_word:
            # if ph == 'SP' and float(midi_dur_in_this_word[0]) < 0.2:
            #     ph = "AP"
            ph_lst.append(ph)
            note_lst.append(note_in_this_word[0])
            midi_dur_lst.append(midi_dur_in_this_word[0])
            is_slur.append('0')
        # step 2.
        #  Deal with the 2nd, 3rd... notes of 'slur' case
        #  j        ie         ie
        #  F#4/Gb4  F#4/Gb4    C#4/Db4
        #  0        0          1
        # is_slur = True, we should repeat the YUNMU to match the 2nd, 3rd... notes.
        if len(note_in_this_word) > 1:
            for idx in range(1, len(note_in_this_word)):
                # if ph_in_this_word == ['n', 'i']:
                #     import pdb
                #     pdb.set_trace()
                # print(ph_in_this_word, note_in_this_word)
                if len(ph_in_this_word)>idx and len(midi_dur_in_this_word)>idx and 'i' in ph_in_this_word[idx] and float(midi_dur_in_this_word[idx]) - float(midi_dur_in_this_word[idx-1]) > 0.2:
                    note_lst[-1]= note_in_this_word[idx]
                

                note_lst.append(note_in_this_word[idx])
                ph_lst.append(ph_in_this_word[-1])   
                midi_dur_lst.append(midi_dur_in_this_word[idx])
                is_slur.append('1')
            
    # print(ph_lst)
    # print(note_lst)
    # print(midi_dur_lst)
    # print(is_slur)

    if len(ph_lst) == len(note_lst) == len(midi_dur_lst):
        print("sucess convert note and midi_dur")
    else:
        print("è¾“å…¥æœ‰è¯¯ï¼Œåˆ†å‰²åçš„éŸ³ç¬¦é•¿åº¦ï¼š{}, éŸ³ç´ é•¿åº¦: {}, æ—¶é•¿é•¿åº¦: {}".format(len(note_lst), len(ph_lst), len(midi_dur_lst)))
        return None

    return ' '.join(ph_lst), ' '.join(note_lst), ' '.join(midi_dur_lst), ' '.join(is_slur)
        

class GradioInfer:
    def __init__(self, exp_name, inference_cls, title, description, article, example_inputs):
        self.exp_name = exp_name
        self.title = title
        self.description = description
        self.article = article
        self.example_inputs = example_inputs
        inference_cls="infer_file.Infer_Fun"
        pkg = ".".join(inference_cls.split(".")[:-1])
        cls_name = inference_cls.split(".")[-1]
        # import pdb
        # pdb.set_trace()
        self.inference_cls = getattr(importlib.import_module(pkg), cls_name)
        
    def clear(self, name, text, notes, notes_duration):
        return '','','','',''

    def select_sid(self, name):
        text = lyrics_dict[Songs_CN_dict[name]]
        return name, text, gr.Dropdown.update(choices=songs_list,value=name)

    def select_style(self, choice_style):
        return gr.Dropdown.update(choices=style_list,value=choice_style)
    
    def select_format(self, create_songs):
        if create_songs==create_list[0]:
            return gr.Dropdown.update(choices=create_list,value=create_list[0]), gr.Dropdown.update(choices=songs_list,value="", visible=True), gr.Dropdown.update(choices=style_list,value="", visible=False), ''
        else:
            return gr.Dropdown.update(choices=create_list,value=create_list[1]), gr.Dropdown.update(choices=songs_list,value="", visible=False), gr.Dropdown.update(choices=style_list, value="", visible=True), ''
    
    def generate_lyrics(self, create_songs, choice_style, name, sid_name, text):
        try:
            if not name:
                return None, None, text, "è¯·è¾“å…¥ä¸»é¢˜ï¼"

            if create_songs==create_list[1]:
                if not choice_style:
                    return None, None, text, "è¯·è¿›è¡Œé£æ ¼é€‰æ‹©"
                text, notes, notes_duration = lyrics_to_melody(name, choice_style)
                
            else:
                notes, notes_duration, text   = gen_songs_needs(name, Songs_CN_dict[sid_name])
            
                len_notes = len(notes.split('|'))
                len_notes_duration = len(notes_duration.split('|'))
                len_text = len(text) - text.count("SP")
                
                print(len_notes, len_notes_duration, len_text)
                
                if len_text!=len_notes_duration:
                    return notes, notes_duration, text, "æ­Œè¯é•¿åº¦ä¸º{}ä¸ªå•è¯ï¼Œéœ€è¦ä¿æŒ{}ä¸ªå•è¯ï¼Œè¯·ç‚¹å‡»ã€ä½¿ç”¨ä¸»é¢˜ã€‘é‡æ–°ç”Ÿæˆ!".format(len_text,len_notes_duration)
                
            text = text.replace("SP", "\n")
            
            return notes, notes_duration, text, "åˆ›ä½œæˆåŠŸï¼Œå¿«ç‚¹å‡»æ­Œå£°åˆæˆå§ï½"
        except:
            return '', '', text, "ä¸å¥½æ„æ€ï¼Œæˆ‘å°è¯•å¤±è´¥äº†ï¼Œè¯·ç‚¹å‡»ã€ä½¿ç”¨ä¸»é¢˜ã€‘é‡æ–°ç„¶æˆ‘é‡æ–°è¯•è¯•ï½"
    
    def greet(self, create_songs, name, text, notes, notes_duration, sid, auto_f0, vc_transform, choice_ckpt, sid_name, Ins):
        # import pdb
        # pdb.set_trace()

        if not text:
            return None, "è¯·è¾“å…¥æˆ–åˆ›ä½œæ­Œè¯"

        if not notes:
            notes = notes_dict[Songs_CN_dict[sid_name]]
            notes_duration = notes_duration_dict[Songs_CN_dict[sid_name]]
                
        len_notes = len(notes.split('|'))
        len_notes_duration = len(notes_duration.split('|'))
        if text[0] == "\n":
            text = text[1:]
        if text[-1]=="\n" and create_songs==create_list[0]:
            text = text[:-1]
        text = text.replace("\n", "SP").replace(" ", "")
        len_text = len(text) - text.count("SP")
        print(len_notes, len_notes_duration, len_text)

        if len_text!=len_notes_duration:
            return None, "æ­Œè¯é•¿åº¦ä¸º{}ä¸ªå•è¯ï¼Œè¯·ä¿æŒ{}ä¸ªå•è¯!".format(len_text,len_notes_duration)

        ph_seq, notes, notes_duration, notes_slur = convert_note_midi_dur(text, notes, notes_duration)

        PUNCS = 'ã€‚ï¼Ÿï¼›ï¼š'
        sents = re.split(rf'([{PUNCS}])', text.replace('\n', ','))
        sents_notes = re.split(rf'([{PUNCS}])', notes.replace('\n', ','))
        sents_notes_dur = re.split(rf'([{PUNCS}])', notes_duration.replace('\n', ','))
        sents_ph_seq = re.split(rf'([{PUNCS}])', ph_seq.replace('\n', ','))
        sents_notes_slur = re.split(rf'([{PUNCS}])', notes_slur.replace('\n', ','))
        
        if sents[-1] not in list(PUNCS):
            sents = sents + ['']
            sents_notes = sents_notes + ['']
            sents_notes_dur = sents_notes_dur + ['']
            sents_ph_seq = sents_ph_seq + ['']
            sents_notes_slur = sents_notes_slur + ['']

        audio_outs = []
        s, n, n_dur, ph, n_slur = "", "", "", "",  ""
        for i in range(0, len(sents), 2):
            if len(sents[i]) > 0:
                s += sents[i] + sents[i + 1]
                n += sents_notes[i] + sents_notes[i+1]
                n_dur += sents_notes_dur[i] + sents_notes_dur[i+1]
                ph += sents_ph_seq[i] + sents_ph_seq[i+1]
                n_slur += sents_notes_slur[i] + sents_notes_slur[i+1]
            if len(s) >= 400 or (i >= len(sents) - 2 and len(s) > 0):
                audio_out = self.infer_ins.infer_once({
                    # 'text': s,
                    # 'notes': n,
                    # 'notes_duration': n_dur,
                    'text': s,
                    'ph_seq': ph,
                    'note_seq': n,
                    'note_dur_seq': n_dur,
                    'is_slur_seq': n_slur,
                    'input_type' : 'phoneme'
                })
                audio_out = audio_out * 32767
                audio_out = audio_out.astype(np.int16)
                audio_outs.append(audio_out)
                audio_outs.append(np.zeros(int(hp['audio_sample_rate'] * 0.3)).astype(np.int16))
                s = ""
                n = ""
        audio_outs = np.concatenate(audio_outs)
        sf.write('temp.wav', audio_outs, hp['audio_sample_rate'])
        output_file_path = "temp.wav"

        if sid != "ğŸ”¥æ˜Ÿè¾‰å¥³éŸ³-å¥³æ­Œæ‰‹ğŸ‘©â€ğŸ¤":
            with torch.no_grad():
                _,  output_file_path = vc_batch_fn(sid, 'temp.wav', auto_f0, vc_transform, choice_ckpt)
        
        if Ins == "æ˜¯":
            if isinstance(output_file_path, tuple):
                sf.write('temp.wav', output_file_path[1], output_file_path[0])
                output_file_path = "temp.wav"

            merge_audio_files(Songs_ST_dict[sid_name], output_file_path, os.path.join("instrument",f"{Songs_CN_dict[sid_name]}"+".wav"), output_file_path, Songs_V_dict[sid_name])

        return output_file_path, "åˆæˆæˆåŠŸï¼Œå¿«å»å¬å¬å§ï½"
    
    def run(self):

        set_hparams(os.path.join(script_path, "model/config.yaml"))
        infer_cls = self.inference_cls
        self.infer_ins: Infer_Fun = infer_cls(hp)
        example_inputs = self.example_inputs
        for i in range(len(example_inputs)):
            text, notes, notes_dur = example_inputs[i].split('<sep>')
            example_inputs[i] = ['', text, notes, notes_dur]
        iface = gr.Blocks()

        with iface:
            
            gr.Markdown(f"<h1 style='text-align: center; margin-bottom: 1rem'>ğŸ’•ğŸ¤ {self.title}</h1>")
            gr.Markdown("## <center>âš¡ åªéœ€3åˆ†é’Ÿè®­ç»ƒï¼Œå¿«é€Ÿå¤åˆ»æ‚¨å–œæ¬¢çš„å£°éŸ³ï¼›åœ¨çº¿ä½“éªŒï¼Œè®©ä½ æ²‰æµ¸å…¶ä¸­ã€‚</center>")
            
            gr.Markdown(value="""
                ### æ³¨æ„â€¼ï¸ï¼šæœ¬åº”ç”¨ä»…ä¾›ä¸ªäººå¨±ä¹å’Œéå•†ä¸šç”¨é€”ï¼Œç¦æ­¢ç”¨äºè¡€è…¥ã€æš´åŠ›ã€æ€§ç›¸å…³ã€æ”¿æ²»ç›¸å…³å†…å®¹

                è”ç³»åˆ¶ä½œè€…ï¼šã€é£æ¡¨&ç™¾åº¦ç ”ç©¶é™¢å¤§æ•°æ®å®éªŒå®¤ã€‘ï¼ˆé™†ç‘¶ã€ç‹ç¡•ã€è¾¹æ±Ÿï¼‰
                """)
            gr.Markdown(value=self.description)
            with gr.Tab("ğŸ¶ - åœ¨çº¿ä½“éªŒ"):
                with gr.Group(): 
                    gr.Markdown(value="""
                        <font size=3> ğŸ™ï¸Step 1: éŸ³è‰²æ¨¡å‹é€‰æ‹©</font>
                        """)
                    with gr.Column():

                        with gr.Row():
                            sid = gr.Dropdown(label="éŸ³è‰²ï¼ˆæ­Œæ‰‹ï¼‰",choices = spks,value=spks[0])
                            exp_sex = gr.Radio(label="é€‰æ‹©ç”·å£°ğŸš¹/å¥³å£°ğŸšº", choices=["ç”·å£°", "å¥³å£°"], value="",visible=False)
                            choice_ckpt = gr.Dropdown(label="æ¨¡å‹é€‰æ‹©", choices=ckpt_list, value="é»˜è®¤")
                            model_load_button = gr.Button(value="åŠ è½½æ¨¡å‹(âš ï¸ç‚¹æˆ‘ç‚¹æˆ‘)", variant="primary")
                        with gr.Row():
                            example_output = gr.Audio(label="éŸ³è‰²é¢„è§ˆ", interactive=False, value="æ˜Ÿè¾‰å¥³éŸ³.wav")
                            sid_output = gr.Textbox(label="Output Message")
                        auto_f0 = gr.Checkbox(label="è‡ªåŠ¨f0é¢„æµ‹ï¼Œé…åˆèšç±»æ¨¡å‹f0é¢„æµ‹æ•ˆæœæ›´å¥½,ä¼šå¯¼è‡´å˜è°ƒåŠŸèƒ½å¤±æ•ˆï¼ˆä»…é™è½¬æ¢è¯­éŸ³ï¼Œæ­Œå£°å‹¾é€‰æ­¤é¡¹ä¼šç©¶æè·‘è°ƒï¼‰", value=False, visible=False)
                        
                with gr.Group(): 
                    gr.Markdown(value="""
                        <font size=3> ğŸ¼Step 2: æ­Œæ›²åˆ›ä½œ</font>
                        """) 
                    with gr.Column():
                        
                        with gr.Row():
                            # with gr.Row():                        
                            create_songs = gr.Dropdown(label="åˆ›ä½œå½¢å¼", choices=create_list, value=create_list[0])
                            name = gr.Textbox(lines=2, placeholder=None, label="è¾“å…¥ä½ æƒ³åˆ›ä½œçš„ä¸»é¢˜ï¼Œä¾‹å¦‚ï¼šå›å®¶ï¼Œæˆ‘ä»¬ä¼šè¿›è¡ŒAIåˆ›ä½œæ­Œè¯å“¦ï½")
                            
                            choice_songs = gr.Dropdown(label="æ¨¡æ¿é€‰æ‹©", choices=songs_list, visible=True)
                            choice_style = gr.Dropdown(label="é£æ ¼é€‰æ‹©", choices=style_list, visible=False)
                            submit1_button = gr.Button(value="æ­Œæ›²åˆ›ä½œ(âš ï¸ç‚¹æˆ‘ç‚¹æˆ‘)", variant="primary")    
                            
                        with gr.Row():
                            text = gr.Textbox(lines=2, placeholder=None, value="", label="åˆ›ä½œæ­Œæ›²é¢„è§ˆ")

                        sid_name = gr.Dropdown(label="æ­Œæ›²",choices = list(Songs_CN_dict.keys()),value="", visible=False)
                        notes = gr.Textbox(lines=2, placeholder=None, value="", label="input note", visible=False)
                        notes_duration = gr.Textbox(lines=2, placeholder=None, value="", label="input duration", visible=False)
                        clear_button = gr.Button(value="æ¸…é™¤ä¿¡æ¯", visible=False)
                with gr.Group(): 
                    gr.Markdown(value="""
                        <font size=3> ğŸ““Step 3: å…¶ä»–è®¾ç½®é€‰é¡¹</font>
                        """) 
                    with gr.Column(): 

                        with gr.Row():
                            Ins = gr.Radio(label="æ˜¯å¦åŠ å…¥ä¼´å¥", choices=["æ˜¯", "å¦"], value="å¦", interactive=True)
                            vc_transform = gr.Number(label="éŸ³è°ƒè°ƒæ•´", value=0)

                with gr.Group(): 
                    gr.Markdown(value="""
                        <font size=3> ğŸ§‘â€ğŸ¤Step 4: æ­Œå£°åˆæˆ</font>
                        """) 
                    with gr.Column(): 

                        with gr.Row():
                            submit2_button = gr.Button(value="æ­Œå£°åˆæˆ(âš ï¸ç‚¹æˆ‘ç‚¹æˆ‘)", variant="primary")
                            output_audio = gr.Audio(label="Output Audio", interactive=False)

                choice_songs.select(self.select_sid, [choice_songs], [sid_name, text, choice_songs])
                create_songs.select(self.select_format, [create_songs], [create_songs, choice_songs, choice_style, text]).then(self.clear, [name, text, notes, notes_duration], [name, text, notes, notes_duration])
                choice_style.select(self.select_style, [choice_style])

                device = gr.Dropdown(label="æ¨ç†è®¾å¤‡, é»˜è®¤ä¸ºè‡ªåŠ¨é€‰æ‹©CPUå’ŒGPU", choices=["Auto",*cuda.keys(),"cpu"], value="Auto", visible=False)
                
                sid.select(refresh_options,[sid, vc_transform, exp_sex],[sid, choice_ckpt, example_output, vc_transform, sid_output])
                
                model_load_button.click(modelAnalysis,[device, sid, sid_output, choice_ckpt],[sid,sid_output])

                submit1_button.click(self.generate_lyrics, [create_songs, choice_style, name, sid_name, text], [notes, notes_duration, text, sid_output])
                
                submit2_button.click(self.greet, [create_songs, name, text, notes, notes_duration,sid, auto_f0, vc_transform, choice_ckpt, sid_name, Ins], [output_audio, sid_output])
                
                clear_button.click(self.clear, [name, text, notes, notes_duration], [name, text, notes, notes_duration])
        

            with gr.Tab("ğŸ”Š - å®šåˆ¶å£°éŸ³"):     
                gr.Markdown(
                    value="step1: å¡«å†™å®éªŒé…ç½®, éœ€æ‰‹å·¥è¾“å…¥æ¨¡å‹åå­—, ä¾‹å¦‚(xiaoming). "
                )
                with gr.Row():
                    with gr.Column():
                        with gr.Row():
                            exp_dir1 = gr.Textbox(label="ç»™å£°éŸ³æ¨¡å‹å–ä¸ªåå­—å§", value="")
                            exp_sex = gr.Radio(label="é€‰æ‹©ç”·å£°ğŸš¹/å¥³å£°ğŸšº", choices=["ç”·å£°", "å¥³å£°"], value="")
                            sr2 = gr.Radio(
                                label=i18n("ç›®æ ‡é‡‡æ ·ç‡"),
                                choices=["40k", "48k"],
                                value="40k",
                                interactive=True,
                                visible=False,
                            )
                            if_f0_3 = gr.Radio(
                                label=i18n("æ¨¡å‹æ˜¯å¦å¸¦éŸ³é«˜æŒ‡å¯¼(å”±æ­Œä¸€å®šè¦, è¯­éŸ³å¯ä»¥ä¸è¦)"),
                                choices=[True, False],
                                value=True,
                                interactive=True,
                                visible=False,
                            )
                            version19 = gr.Radio(
                                label=i18n("ç‰ˆæœ¬"),
                                choices=["v1", "v2"],
                                value="v2",
                                interactive=True,
                                visible=False,
                            )
                            np7 = gr.Slider(
                                minimum=0,
                                maximum=config.n_cpu,
                                step=1,
                                label=i18n("æå–éŸ³é«˜å’Œå¤„ç†æ•°æ®ä½¿ç”¨çš„CPUè¿›ç¨‹æ•°"),
                                value=int(np.ceil(config.n_cpu / 1.5)),
                                interactive=True,
                                visible=False,
                            )

                        gr.Markdown(
                            value="step2: âºï¸è¯·å½•åˆ¶æˆ–ä¸Šä¼ å¹²å£°æ•°æ®ï¼Œæ”¯æŒæ‰¹é‡éŸ³é¢‘æ–‡ä»¶çš„ä¸Šä¼ ï¼Œä¼˜å…ˆå¤„ç†éº¦å…‹é£å£°éŸ³. "
                        )
                        with gr.Row():
                            # with gr.Row():
                                
                            #     trainset_dir4 = gr.File(
                            #         label="ä¸Šä¼ å¾…è®­ç»ƒå£°éŸ³æ–‡ä»¶(è¯·ä¸Šä¼ å¹²å£°), å¯æ‰¹é‡è¾“å…¥éŸ³é¢‘æ–‡ä»¶", file_count="multiple"
                            #     )
                            with gr.Row():
                                with gr.Column():
                                    record_audio_prompt = gr.Audio(label='è¯·åœ¨æ­¤ç”¨éº¦å…‹é£å½•åˆ¶æ‚¨å–œæ¬¢çš„å£°éŸ³', source='microphone', interactive=True, type="filepath", autoplay="True")
                                    trainset_dir4 = gr.File(
                                    label="ä¸Šä¼ å¾…è®­ç»ƒå£°éŸ³æ–‡ä»¶(è¯·ä¸Šä¼ å¹²å£°), å¯æ‰¹é‡è¾“å…¥éŸ³é¢‘æ–‡ä»¶", file_count="multiple"
                                )  

                                spk_id5 = gr.Slider(
                                    minimum=0,
                                    maximum=4,
                                    step=1,
                                    label=i18n("è¯·æŒ‡å®šè¯´è¯äººid"),
                                    value=0,
                                    interactive=True,
                                    visible=False,
                                )
                                but1 = gr.Button(i18n("å¤„ç†æ•°æ®"), variant="primary", visible=False,)
                                info1 = gr.Textbox(label=i18n("è¾“å‡ºä¿¡æ¯"), value="", visible=False,)

                                
                        with gr.Row():
                            with gr.Column():
                                gpus6 = gr.Textbox(
                                    label=i18n("ä»¥-åˆ†éš”è¾“å…¥ä½¿ç”¨çš„å¡å·, ä¾‹å¦‚   0-1-2   ä½¿ç”¨å¡0å’Œå¡1å’Œå¡2"),
                                    value=gpus,
                                    interactive=True,
                                    visible=False,
                                )
                                gpu_info9 = gr.Textbox(
                                    label=i18n("æ˜¾å¡ä¿¡æ¯"), value=gpu_info, visible=False,
                                )
                            with gr.Column():
                                f0method8 = gr.Radio(
                                    label=i18n(
                                        "é€‰æ‹©éŸ³é«˜æå–ç®—æ³•:è¾“å…¥æ­Œå£°å¯ç”¨pmæé€Ÿ,é«˜è´¨é‡è¯­éŸ³ä½†CPUå·®å¯ç”¨dioæé€Ÿ,harvestè´¨é‡æ›´å¥½ä½†æ…¢,rmvpeæ•ˆæœæœ€å¥½ä¸”å¾®åƒCPU/GPU"
                                    ),
                                    choices=["pm", "harvest", "dio", "rmvpe", "rmvpe_gpu"],
                                    value="rmvpe_gpu",
                                    interactive=True,
                                    visible=False,
                                )
                                gpus_rmvpe = gr.Textbox(
                                    label=i18n(
                                        "rmvpeå¡å·é…ç½®ï¼šä»¥-åˆ†éš”è¾“å…¥ä½¿ç”¨çš„ä¸åŒè¿›ç¨‹å¡å·,ä¾‹å¦‚0-0-1ä½¿ç”¨åœ¨å¡0ä¸Šè·‘2ä¸ªè¿›ç¨‹å¹¶åœ¨å¡1ä¸Šè·‘1ä¸ªè¿›ç¨‹"
                                    ),
                                    value="%s-%s" % (gpus, gpus),
                                    interactive=True,
                                    visible=False,
                                )
                            but2 = gr.Button(i18n("ç‰¹å¾æå–"), variant="primary",visible=False,)
                            info2 = gr.Textbox(label=i18n("è¾“å‡ºä¿¡æ¯"), value="", max_lines=8, visible=False,)



                        with gr.Row():
                            save_epoch10 = gr.Slider(
                                minimum=1,
                                maximum=50,
                                step=1,
                                label=i18n("ä¿å­˜é¢‘ç‡save_every_epoch"),
                                value=5,
                                interactive=True,
                                visible=False,
                            )
                            total_epoch11 = gr.Slider(
                                minimum=2,
                                maximum=1000,
                                step=1,
                                label=i18n("æ€»è®­ç»ƒè½®æ•°total_epoch"),
                                value=20,
                                interactive=True,
                                visible=False,
                            )
                            batch_size12 = gr.Slider(
                                minimum=1,
                                maximum=40,
                                step=1,
                                label=i18n("æ¯å¼ æ˜¾å¡çš„batch_size"),
                                value=default_batch_size,
                                interactive=True,
                                visible=False,
                            )
                            if_save_latest13 = gr.Radio(
                                label=i18n("æ˜¯å¦ä»…ä¿å­˜æœ€æ–°çš„ckptæ–‡ä»¶ä»¥èŠ‚çœç¡¬ç›˜ç©ºé—´"),
                                choices=[i18n("æ˜¯"), i18n("å¦")],
                                value=i18n("å¦"),
                                interactive=True,
                                visible=False,
                            )
                            if_cache_gpu17 = gr.Radio(
                                label=i18n(
                                    "æ˜¯å¦ç¼“å­˜æ‰€æœ‰è®­ç»ƒé›†è‡³æ˜¾å­˜. 10minä»¥ä¸‹å°æ•°æ®å¯ç¼“å­˜ä»¥åŠ é€Ÿè®­ç»ƒ, å¤§æ•°æ®ç¼“å­˜ä¼šç‚¸æ˜¾å­˜ä¹ŸåŠ ä¸äº†å¤šå°‘é€Ÿ"
                                ),
                                choices=[i18n("æ˜¯"), i18n("å¦")],
                                value=i18n("å¦"),
                                interactive=True,
                                visible=False,
                            )
                            if_save_every_weights18 = gr.Radio(
                                label=i18n("æ˜¯å¦åœ¨æ¯æ¬¡ä¿å­˜æ—¶é—´ç‚¹å°†æœ€ç»ˆå°æ¨¡å‹ä¿å­˜è‡³weightsæ–‡ä»¶å¤¹"),
                                choices=[i18n("æ˜¯"), i18n("å¦")],
                                value=i18n("å¦"),
                                interactive=True,
                                visible=False,
                            )
                        with gr.Row():
                            pretrained_G14 = gr.Textbox(
                                label=i18n("åŠ è½½é¢„è®­ç»ƒåº•æ¨¡Gè·¯å¾„"),
                                value="assets/pretrained_v2/f0G40k.pth",
                                interactive=True,
                                visible=False,
                            )
                            pretrained_D15 = gr.Textbox(
                                label=i18n("åŠ è½½é¢„è®­ç»ƒåº•æ¨¡Dè·¯å¾„"),
                                value="assets/pretrained_v2/f0D40k.pth",
                                interactive=True,
                                visible=False,
                                
                            )

                            gpus16 = gr.Textbox(
                                label=i18n("ä»¥-åˆ†éš”è¾“å…¥ä½¿ç”¨çš„å¡å·, ä¾‹å¦‚   0-1-2   ä½¿ç”¨å¡0å’Œå¡1å’Œå¡2"),
                                value=gpus.split("-")[0],
                                interactive=True,
                                visible=False,
                            )
                            but3 = gr.Button(i18n("è®­ç»ƒæ¨¡å‹"), variant="primary", visible=False,)
                            but4 = gr.Button(i18n("è®­ç»ƒç‰¹å¾ç´¢å¼•"), variant="primary", visible=False,)
                            but5 = gr.Button("ä¸€é”®è®­ç»ƒ(âš ï¸ç‚¹æˆ‘ç‚¹æˆ‘)", variant="primary")

                    with gr.Column():
                        info3 = gr.Textbox(label="â€¼ï¸ è¾“å‡ºä¿¡æ¯ï¼Œè¯·ç­‰å¾…æ—¥å¿—å‡ºç°â€œå…¨æµç¨‹ç»“æŸï¼â€", value="", max_lines=10)
                        train_text = gr.Textbox(lines=22, placeholder=True, value=TRAIN_DATA, label="è¯·é˜…è¯»å¹¶å½•éŸ³ä¸‹é¢è¿™æ®µè¯", interactive=False)
                    


                f0method8.change(
                    fn=change_f0_method,
                    inputs=[f0method8],
                    outputs=[gpus_rmvpe],
                )

                sr2.change(
                    change_sr2,
                    [sr2, if_f0_3, version19],
                    [pretrained_G14, pretrained_D15],
                )
                version19.change(
                    change_version19,
                    [sr2, if_f0_3, version19],
                    [pretrained_G14, pretrained_D15, sr2],
                )
                if_f0_3.change(
                    change_f0,
                    [if_f0_3, sr2, version19],
                    [f0method8, gpus_rmvpe, pretrained_G14, pretrained_D15],
                )

                but5.click(
                    train1key,
                    [   sid,
                        exp_sex,
                        exp_dir1,
                        sr2,
                        if_f0_3,
                        record_audio_prompt,
                        trainset_dir4,
                        spk_id5,
                        np7,
                        f0method8,
                        save_epoch10,
                        total_epoch11,
                        batch_size12,
                        if_save_latest13,
                        pretrained_G14,
                        pretrained_D15,
                        gpus16,
                        if_cache_gpu17,
                        if_save_every_weights18,
                        version19,
                        gpus_rmvpe,
                    ],
                    [info3, sid],
                    api_name="train_start_all",
                ).then(refresh_options,[sid, vc_transform, exp_sex],[sid, choice_ckpt, example_output, vc_transform, sid_output]).then(modelAnalysis,[device, sid, sid_output, choice_ckpt],[sid,sid_output])

        # iface.launch(enable_queue=True)
        iface.queue(concurrency_count=511, max_size=1022).launch(share=True)


if __name__ == '__main__':
    gradio_config = yaml.safe_load(open('settings-1.yaml'))
    g = GradioInfer(**gradio_config)
    g.run()